{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/mnist.pkl.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ffbbfca15728>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3_nn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyMLP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLeNetConvPoolLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropConnect\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3bmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_lenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest_lenet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnkerns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/extern/final/dropconnect/src/hw3bmnist.py\u001b[0m in \u001b[0;36mtest_lenet\u001b[1;34m(learning_rate, n_epochs, nkerns, batch_size, verbose, fileName)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;31m# Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;31m# Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/ubuntu/mnist.pkl.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m# Issue #13781: os.fdopen() creates a fileobj with a bogus name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/mnist.pkl.gz'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3bmnist import test_lenet\n",
    "test_lenet(batch_size = 20,nkerns = [32,64],learning_rate = 0.01,verbose=True,n_epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0d945e34113d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3b\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_lenet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_lenet3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m test_lenet3(learning_rate=0.1, n_epochs=100, nkerns=[16, 32, 64],\n\u001b[1;32m---> 11\u001b[1;33m             batch_size=20, verbose=True, fileName = 'predictions')\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3b.py\u001b[0m in \u001b[0;36mtest_lenet3\u001b[1;34m(learning_rate, n_epochs, nkerns, batch_size, verbose, fileName)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0mrng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m23455\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m     \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mtrain_set_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3_utils.pyc\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(ds_rate, theano_shared)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtheano_shared\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mtest_set_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mvalid_set_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_set_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mtrain_set_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshared_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3_utils.pyc\u001b[0m in \u001b[0;36mshared_dataset\u001b[1;34m(data_xy, borrow)\u001b[0m\n\u001b[0;32m     29\u001b[0m     shared_x = theano.shared(numpy.asarray(data_x,\n\u001b[0;32m     30\u001b[0m                                            dtype=theano.config.floatX),\n\u001b[1;32m---> 31\u001b[1;33m                              borrow=borrow)\n\u001b[0m\u001b[0;32m     32\u001b[0m     shared_y = theano.shared(numpy.asarray(data_y,\n\u001b[0;32m     33\u001b[0m                                            dtype=theano.config.floatX),\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/sharedvalue.pyc\u001b[0m in \u001b[0;36mshared\u001b[1;34m(value, name, strict, allow_downcast, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 var = ctor(value, name=name, strict=strict,\n\u001b[1;32m--> 208\u001b[1;33m                            allow_downcast=allow_downcast, **kwargs)\n\u001b[0m\u001b[0;32m    209\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_tag_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/sandbox/cuda/var.pyc\u001b[0m in \u001b[0;36mfloat32_shared_constructor\u001b[1;34m(value, name, strict, allow_downcast, borrow, broadcastable)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;31m# type.broadcastable is guaranteed to be a tuple, which this next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# function requires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mdeviceval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_support_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3b import test_lenet, test_lenet3\n",
    "test_lenet3(learning_rate=0.1, n_epochs=100, nkerns=[16, 32, 64],\n",
    "            batch_size=20, verbose=True, fileName = 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "Yo man\n",
      "Model building complete\n",
      "Commpiling the train model function\n",
      "... training\n",
      "print(validation_frequency) = 3296\n",
      "training @ iter =  0\n",
      "training @ iter =  100\n",
      "training @ iter =  200\n",
      "training @ iter =  300\n",
      "training @ iter =  400\n",
      "training @ iter =  500\n",
      "training @ iter =  600\n",
      "training @ iter =  700\n",
      "training @ iter =  800\n",
      "training @ iter =  900\n",
      "training @ iter =  1000\n",
      "training @ iter =  1100\n",
      "training @ iter =  1200\n",
      "training @ iter =  1300\n",
      "training @ iter =  1400\n",
      "training @ iter =  1500\n",
      "training @ iter =  1600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-99c6c153b479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3_nn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyMLP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLeNetConvPoolLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropConnect\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3b\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_mlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest_mlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3b.py\u001b[0m in \u001b[0;36mtest_mlp\u001b[1;34m(learning_rate, L1_reg, L2_reg, n_epochs, batch_size, n_hidden, verbose, fileName)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     predictions = train_nn(train_model, validate_model, test_model, getPredictedValue,\n\u001b[1;32m--> 618\u001b[1;33m         n_train_batches, n_valid_batches, n_test_batches, n_epochs, verbose)\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3_nn.pyc\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(train_model, validate_model, test_model, getPredictedValue, n_train_batches, n_valid_batches, n_test_batches, n_epochs, verbose)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training @ iter = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalidation_frequency\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/tensor/raw_random.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, out_)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mrout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3b import test_mlp\n",
    "test_mlp(batch_size = 20,n_epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 0.12941176,  0.11764706,  0.14901961, ...,  0.40392157,\n",
       "           0.41568627,  0.30980392],\n",
       "         [ 0.32941176,  0.29803922,  0.23137255, ...,  0.40392157,\n",
       "           0.38431373,  0.31372549],\n",
       "         [ 0.0745098 ,  0.21176471,  0.43137255, ...,  0.24705882,\n",
       "           0.56862745,  0.90588235],\n",
       "         ..., \n",
       "         [ 0.47843137,  0.47843137,  0.51764706, ...,  0.21176471,\n",
       "           0.20784314,  0.38039216],\n",
       "         [ 0.41568627,  0.43921569,  0.56470588, ...,  0.54117647,\n",
       "           0.53333333,  0.48235294],\n",
       "         [ 0.87058824,  0.90588235,  0.90196078, ...,  0.8627451 ,\n",
       "           0.88627451,  0.88627451]]),\n",
       "  array([1, 9, 2, ..., 2, 4, 1], dtype=uint8)],\n",
       " [array([[ 0.8627451 ,  0.88627451,  0.87843137, ...,  0.88235294,\n",
       "           0.89803922,  0.90196078],\n",
       "         [ 0.86666667,  0.90196078,  0.88235294, ...,  0.8627451 ,\n",
       "           0.89803922,  0.89411765],\n",
       "         [ 0.58431373,  0.49411765,  0.43921569, ...,  0.23137255,\n",
       "           0.17254902,  0.14509804],\n",
       "         ..., \n",
       "         [ 0.36078431,  0.30588235,  0.39607843, ...,  0.85490196,\n",
       "           0.85098039,  0.85490196],\n",
       "         [ 0.74509804,  0.7372549 ,  0.74901961, ...,  0.85490196,\n",
       "           0.83529412,  0.81960784],\n",
       "         [ 0.84705882,  0.85098039,  0.83137255, ...,  0.70980392,\n",
       "           0.69803922,  0.67058824]]),\n",
       "  array([8, 8, 6, ..., 1, 6, 9], dtype=uint8)],\n",
       " (array([[ 0.14901961,  0.40392157,  0.23529412, ...,  0.16470588,\n",
       "           0.44313725,  0.27843137],\n",
       "         [ 0.50588235,  0.55686275,  0.6       , ...,  0.48235294,\n",
       "           0.50980392,  0.61176471],\n",
       "         [ 0.58823529,  0.62745098,  0.6627451 , ...,  0.59607843,\n",
       "           0.65882353,  0.71764706],\n",
       "         ..., \n",
       "         [ 0.45098039,  0.51764706,  0.55686275, ...,  0.56470588,\n",
       "           0.61568627,  0.64705882],\n",
       "         [ 0.37647059,  0.25490196,  0.18431373, ...,  0.40784314,\n",
       "           0.33333333,  0.26666667],\n",
       "         [ 0.39607843,  0.29411765,  0.23529412, ...,  0.4       ,\n",
       "           0.27843137,  0.19607843]]),\n",
       "  array([5, 2, 1, ..., 7, 6, 7], dtype=uint8))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3b import test_mlp\n",
    "load_data(theano_shared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12941176,  0.11764706,  0.14901961, ...,  0.40392157,\n",
       "         0.41568627,  0.30980392],\n",
       "       [ 0.32941176,  0.29803922,  0.23137255, ...,  0.40392157,\n",
       "         0.38431373,  0.31372549],\n",
       "       [ 0.0745098 ,  0.21176471,  0.43137255, ...,  0.24705882,\n",
       "         0.56862745,  0.90588235],\n",
       "       ..., \n",
       "       [ 0.47843137,  0.47843137,  0.51764706, ...,  0.21176471,\n",
       "         0.20784314,  0.38039216],\n",
       "       [ 0.41568627,  0.43921569,  0.56470588, ...,  0.54117647,\n",
       "         0.53333333,  0.48235294],\n",
       "       [ 0.87058824,  0.90588235,  0.90196078, ...,  0.8627451 ,\n",
       "         0.88627451,  0.88627451]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(theano_shared=False)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[array([[ 59,  43,  50, ..., 140,  84,  72],\n",
       "         [154, 126, 105, ..., 139, 142, 144],\n",
       "         [255, 253, 253, ...,  83,  83,  84],\n",
       "         ..., \n",
       "         [ 69,  62,  58, ...,  91,  87, 100],\n",
       "         [158, 158, 158, ...,  54,  68,  74],\n",
       "         [196, 196, 193, ..., 165, 167, 166]], dtype=uint8), array([[6],\n",
       "         [9],\n",
       "         [9],\n",
       "         ..., \n",
       "         [4],\n",
       "         [8],\n",
       "         [9]], dtype=uint8)], [array([[140, 146, 143, ...,  78,  64,  78],\n",
       "         [100, 122,  87, ..., 160, 158, 150],\n",
       "         [ 19,  21,  27, ...,  85,  64,  58],\n",
       "         ..., \n",
       "         [ 71,  60,  74, ...,  68,  69,  68],\n",
       "         [250, 254, 211, ..., 215, 255, 254],\n",
       "         [ 62,  61,  60, ..., 130, 130, 131]], dtype=uint8), array([[4],\n",
       "         [2],\n",
       "         [2],\n",
       "         [9],\n",
       "         [0],\n",
       "         [3],\n",
       "         [3],\n",
       "         [1],\n",
       "         [3],\n",
       "         [0],\n",
       "         [4],\n",
       "         [2],\n",
       "         [1],\n",
       "         [4],\n",
       "         [0],\n",
       "         [8],\n",
       "         [2],\n",
       "         [1],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [8],\n",
       "         [3],\n",
       "         [9],\n",
       "         [9],\n",
       "         [9],\n",
       "         [9],\n",
       "         [6],\n",
       "         [5],\n",
       "         [0],\n",
       "         [8],\n",
       "         [2],\n",
       "         [3],\n",
       "         [5],\n",
       "         [9],\n",
       "         [8],\n",
       "         [2],\n",
       "         [8],\n",
       "         [3],\n",
       "         [4],\n",
       "         [1],\n",
       "         [1],\n",
       "         [7],\n",
       "         [6],\n",
       "         [9],\n",
       "         [2],\n",
       "         [1],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [1],\n",
       "         [8],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [3],\n",
       "         [4],\n",
       "         [0],\n",
       "         [8],\n",
       "         [0],\n",
       "         [9],\n",
       "         [1],\n",
       "         [2],\n",
       "         [8],\n",
       "         [0],\n",
       "         [1],\n",
       "         [7],\n",
       "         [7],\n",
       "         [3],\n",
       "         [4],\n",
       "         [7],\n",
       "         [8],\n",
       "         [0],\n",
       "         [2],\n",
       "         [7],\n",
       "         [1],\n",
       "         [3],\n",
       "         [7],\n",
       "         [4],\n",
       "         [6],\n",
       "         [1],\n",
       "         [7],\n",
       "         [6],\n",
       "         [1],\n",
       "         [2],\n",
       "         [6],\n",
       "         [9],\n",
       "         [8],\n",
       "         [2],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [9],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [2],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [9],\n",
       "         [3],\n",
       "         [8],\n",
       "         [8],\n",
       "         [7],\n",
       "         [3],\n",
       "         [6],\n",
       "         [1],\n",
       "         [2],\n",
       "         [9],\n",
       "         [8],\n",
       "         [8],\n",
       "         [1],\n",
       "         [0],\n",
       "         [3],\n",
       "         [0],\n",
       "         [8],\n",
       "         [0],\n",
       "         [0],\n",
       "         [6],\n",
       "         [6],\n",
       "         [1],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [7],\n",
       "         [5],\n",
       "         [3],\n",
       "         [8],\n",
       "         [2],\n",
       "         [1],\n",
       "         [9],\n",
       "         [0],\n",
       "         [4],\n",
       "         [6],\n",
       "         [9],\n",
       "         [2],\n",
       "         [3],\n",
       "         [9],\n",
       "         [4],\n",
       "         [1],\n",
       "         [4],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [8],\n",
       "         [4],\n",
       "         [3],\n",
       "         [0],\n",
       "         [6],\n",
       "         [8],\n",
       "         [8],\n",
       "         [6],\n",
       "         [2],\n",
       "         [3],\n",
       "         [3],\n",
       "         [7],\n",
       "         [3],\n",
       "         [5],\n",
       "         [2],\n",
       "         [9],\n",
       "         [6],\n",
       "         [0],\n",
       "         [2],\n",
       "         [3],\n",
       "         [5],\n",
       "         [2],\n",
       "         [4],\n",
       "         [9],\n",
       "         [5],\n",
       "         [1],\n",
       "         [6],\n",
       "         [0],\n",
       "         [3],\n",
       "         [3],\n",
       "         [7],\n",
       "         [3],\n",
       "         [7],\n",
       "         [9],\n",
       "         [8],\n",
       "         [1],\n",
       "         [5],\n",
       "         [2],\n",
       "         [8],\n",
       "         [0],\n",
       "         [2],\n",
       "         [9],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [2],\n",
       "         [6],\n",
       "         [7],\n",
       "         [4],\n",
       "         [2],\n",
       "         [4],\n",
       "         [5],\n",
       "         [8],\n",
       "         [7],\n",
       "         [6],\n",
       "         [1],\n",
       "         [1],\n",
       "         [9],\n",
       "         [5],\n",
       "         [9],\n",
       "         [7],\n",
       "         [2],\n",
       "         [1],\n",
       "         [2],\n",
       "         [9],\n",
       "         [6],\n",
       "         [8],\n",
       "         [0],\n",
       "         [3],\n",
       "         [7],\n",
       "         [7],\n",
       "         [7],\n",
       "         [8],\n",
       "         [2],\n",
       "         [3],\n",
       "         [9],\n",
       "         [0],\n",
       "         [4],\n",
       "         [1],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [0],\n",
       "         [6],\n",
       "         [6],\n",
       "         [7],\n",
       "         [2],\n",
       "         [6],\n",
       "         [9],\n",
       "         [7],\n",
       "         [9],\n",
       "         [6],\n",
       "         [6],\n",
       "         [1],\n",
       "         [3],\n",
       "         [2],\n",
       "         [4],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [4],\n",
       "         [2],\n",
       "         [6],\n",
       "         [0],\n",
       "         [8],\n",
       "         [4],\n",
       "         [4],\n",
       "         [9],\n",
       "         [8],\n",
       "         [1],\n",
       "         [5],\n",
       "         [8],\n",
       "         [1],\n",
       "         [1],\n",
       "         [8],\n",
       "         [8],\n",
       "         [9],\n",
       "         [7],\n",
       "         [2],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [9],\n",
       "         [6],\n",
       "         [7],\n",
       "         [5],\n",
       "         [0],\n",
       "         [8],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [5],\n",
       "         [0],\n",
       "         [5],\n",
       "         [0],\n",
       "         [2],\n",
       "         [3],\n",
       "         [0],\n",
       "         [3],\n",
       "         [7],\n",
       "         [5],\n",
       "         [0],\n",
       "         [2],\n",
       "         [3],\n",
       "         [2],\n",
       "         [3],\n",
       "         [5],\n",
       "         [9],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [8],\n",
       "         [3],\n",
       "         [9],\n",
       "         [1],\n",
       "         [7],\n",
       "         [3],\n",
       "         [0],\n",
       "         [2],\n",
       "         [0],\n",
       "         [7],\n",
       "         [5],\n",
       "         [1],\n",
       "         [1],\n",
       "         [2],\n",
       "         [6],\n",
       "         [6],\n",
       "         [1],\n",
       "         [6],\n",
       "         [8],\n",
       "         [0],\n",
       "         [8],\n",
       "         [1],\n",
       "         [0],\n",
       "         [7],\n",
       "         [2],\n",
       "         [7],\n",
       "         [3],\n",
       "         [2],\n",
       "         [3],\n",
       "         [1],\n",
       "         [9],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [9],\n",
       "         [2],\n",
       "         [4],\n",
       "         [3],\n",
       "         [8],\n",
       "         [3],\n",
       "         [8],\n",
       "         [7],\n",
       "         [2],\n",
       "         [4],\n",
       "         [2],\n",
       "         [8],\n",
       "         [4],\n",
       "         [4],\n",
       "         [2],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [9],\n",
       "         [4],\n",
       "         [6],\n",
       "         [7],\n",
       "         [0],\n",
       "         [4],\n",
       "         [4],\n",
       "         [1],\n",
       "         [8],\n",
       "         [6],\n",
       "         [2],\n",
       "         [7],\n",
       "         [4],\n",
       "         [3],\n",
       "         [1],\n",
       "         [0],\n",
       "         [7],\n",
       "         [0],\n",
       "         [9],\n",
       "         [5],\n",
       "         [8],\n",
       "         [0],\n",
       "         [1],\n",
       "         [6],\n",
       "         [9],\n",
       "         [5],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2],\n",
       "         [8],\n",
       "         [5],\n",
       "         [4],\n",
       "         [0],\n",
       "         [5],\n",
       "         [1],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [9],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [6],\n",
       "         [1],\n",
       "         [2],\n",
       "         [7],\n",
       "         [8],\n",
       "         [1],\n",
       "         [9],\n",
       "         [0],\n",
       "         [6],\n",
       "         [8],\n",
       "         [6],\n",
       "         [0],\n",
       "         [8],\n",
       "         [9],\n",
       "         [2],\n",
       "         [3],\n",
       "         [7],\n",
       "         [6],\n",
       "         [2],\n",
       "         [9],\n",
       "         [8],\n",
       "         [8],\n",
       "         [6],\n",
       "         [3],\n",
       "         [0],\n",
       "         [6],\n",
       "         [9],\n",
       "         [5],\n",
       "         [9],\n",
       "         [0],\n",
       "         [7],\n",
       "         [2],\n",
       "         [0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [4],\n",
       "         [1],\n",
       "         [7],\n",
       "         [5],\n",
       "         [5],\n",
       "         [2],\n",
       "         [9],\n",
       "         [2],\n",
       "         [0],\n",
       "         [5],\n",
       "         [7],\n",
       "         [4],\n",
       "         [7],\n",
       "         [7],\n",
       "         [2],\n",
       "         [7],\n",
       "         [6],\n",
       "         [5],\n",
       "         [1],\n",
       "         [5],\n",
       "         [9],\n",
       "         [7],\n",
       "         [2],\n",
       "         [0],\n",
       "         [8],\n",
       "         [9],\n",
       "         [8],\n",
       "         [6],\n",
       "         [8],\n",
       "         [5],\n",
       "         [0],\n",
       "         [7],\n",
       "         [7],\n",
       "         [8],\n",
       "         [2],\n",
       "         [1],\n",
       "         [6],\n",
       "         [1],\n",
       "         [3],\n",
       "         [1],\n",
       "         [6],\n",
       "         [6],\n",
       "         [8],\n",
       "         [2],\n",
       "         [3],\n",
       "         [7],\n",
       "         [9],\n",
       "         [8],\n",
       "         [3],\n",
       "         [8],\n",
       "         [5],\n",
       "         [7],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [7],\n",
       "         [4],\n",
       "         [2],\n",
       "         [0],\n",
       "         [4],\n",
       "         [9],\n",
       "         [4],\n",
       "         [2],\n",
       "         [7],\n",
       "         [7],\n",
       "         [4],\n",
       "         [4],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [9],\n",
       "         [0],\n",
       "         [9],\n",
       "         [8],\n",
       "         [6],\n",
       "         [4],\n",
       "         [7],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [6],\n",
       "         [0],\n",
       "         [2],\n",
       "         [1],\n",
       "         [0],\n",
       "         [2],\n",
       "         [8],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [9],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [8],\n",
       "         [5],\n",
       "         [1],\n",
       "         [1],\n",
       "         [8],\n",
       "         [9],\n",
       "         [0],\n",
       "         [6],\n",
       "         [4],\n",
       "         [8],\n",
       "         [4],\n",
       "         [5],\n",
       "         [7],\n",
       "         [1],\n",
       "         [4],\n",
       "         [6],\n",
       "         [2],\n",
       "         [2],\n",
       "         [6],\n",
       "         [8],\n",
       "         [2],\n",
       "         [9],\n",
       "         [2],\n",
       "         [2],\n",
       "         [7],\n",
       "         [1],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [1],\n",
       "         [0],\n",
       "         [8],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [7],\n",
       "         [8],\n",
       "         [9],\n",
       "         [3],\n",
       "         [6],\n",
       "         [1],\n",
       "         [2],\n",
       "         [1],\n",
       "         [2],\n",
       "         [2],\n",
       "         [7],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [2],\n",
       "         [5],\n",
       "         [7],\n",
       "         [2],\n",
       "         [2],\n",
       "         [7],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [5],\n",
       "         [1],\n",
       "         [0],\n",
       "         [2],\n",
       "         [9],\n",
       "         [8],\n",
       "         [3],\n",
       "         [9],\n",
       "         [1],\n",
       "         [2],\n",
       "         [0],\n",
       "         [5],\n",
       "         [9],\n",
       "         [5],\n",
       "         [9],\n",
       "         [3],\n",
       "         [1],\n",
       "         [0],\n",
       "         [3],\n",
       "         [3],\n",
       "         [0],\n",
       "         [4],\n",
       "         [0],\n",
       "         [8],\n",
       "         [4],\n",
       "         [0],\n",
       "         [1],\n",
       "         [7],\n",
       "         [5],\n",
       "         [8],\n",
       "         [3],\n",
       "         [6],\n",
       "         [9],\n",
       "         [8],\n",
       "         [7],\n",
       "         [2],\n",
       "         [8],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [2],\n",
       "         [6],\n",
       "         [7],\n",
       "         [4],\n",
       "         [2],\n",
       "         [7],\n",
       "         [5],\n",
       "         [5],\n",
       "         [4],\n",
       "         [8],\n",
       "         [8],\n",
       "         [1],\n",
       "         [3],\n",
       "         [8],\n",
       "         [5],\n",
       "         [4],\n",
       "         [8],\n",
       "         [9],\n",
       "         [6],\n",
       "         [9],\n",
       "         [4],\n",
       "         [3],\n",
       "         [0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [2],\n",
       "         [4],\n",
       "         [6],\n",
       "         [8],\n",
       "         [8],\n",
       "         [5],\n",
       "         [0],\n",
       "         [3],\n",
       "         [1],\n",
       "         [8],\n",
       "         [3],\n",
       "         [0],\n",
       "         [7],\n",
       "         [9],\n",
       "         [8],\n",
       "         [8],\n",
       "         [9],\n",
       "         [5],\n",
       "         [2],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [8],\n",
       "         [9],\n",
       "         [8],\n",
       "         [4],\n",
       "         [8],\n",
       "         [0],\n",
       "         [5],\n",
       "         [7],\n",
       "         [1],\n",
       "         [4],\n",
       "         [8],\n",
       "         [8],\n",
       "         [3],\n",
       "         [4],\n",
       "         [0],\n",
       "         [0],\n",
       "         [5],\n",
       "         [8],\n",
       "         [3],\n",
       "         [9],\n",
       "         [3],\n",
       "         [5],\n",
       "         [9],\n",
       "         [9],\n",
       "         [6],\n",
       "         [5],\n",
       "         [8],\n",
       "         [6],\n",
       "         [3],\n",
       "         [7],\n",
       "         [2],\n",
       "         [4],\n",
       "         [0],\n",
       "         [9],\n",
       "         [2],\n",
       "         [1],\n",
       "         [0],\n",
       "         [7],\n",
       "         [3],\n",
       "         [9],\n",
       "         [8],\n",
       "         [8],\n",
       "         [4],\n",
       "         [7],\n",
       "         [7],\n",
       "         [6],\n",
       "         [9],\n",
       "         [5],\n",
       "         [8],\n",
       "         [4],\n",
       "         [6],\n",
       "         [2],\n",
       "         [2],\n",
       "         [7],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [9],\n",
       "         [2],\n",
       "         [7],\n",
       "         [6],\n",
       "         [8],\n",
       "         [1],\n",
       "         [1],\n",
       "         [5],\n",
       "         [8],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [0],\n",
       "         [3],\n",
       "         [6],\n",
       "         [1],\n",
       "         [0],\n",
       "         [6],\n",
       "         [2],\n",
       "         [6],\n",
       "         [0],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [2],\n",
       "         [6],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [7],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [5],\n",
       "         [7],\n",
       "         [1],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [7],\n",
       "         [4],\n",
       "         [4],\n",
       "         [1],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [8],\n",
       "         [9],\n",
       "         [6],\n",
       "         [7],\n",
       "         [2],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [7],\n",
       "         [8],\n",
       "         [6],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2],\n",
       "         [2],\n",
       "         [5],\n",
       "         [7],\n",
       "         [1],\n",
       "         [9],\n",
       "         [6],\n",
       "         [1],\n",
       "         [9],\n",
       "         [5],\n",
       "         [9],\n",
       "         [0],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [3],\n",
       "         [8],\n",
       "         [0],\n",
       "         [6],\n",
       "         [7],\n",
       "         [1],\n",
       "         [7],\n",
       "         [4],\n",
       "         [9],\n",
       "         [8],\n",
       "         [2],\n",
       "         [6],\n",
       "         [7],\n",
       "         [3],\n",
       "         [0],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [5],\n",
       "         [7],\n",
       "         [1],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [9],\n",
       "         [8],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [1],\n",
       "         [6],\n",
       "         [7],\n",
       "         [4],\n",
       "         [0],\n",
       "         [1],\n",
       "         [6],\n",
       "         [3],\n",
       "         [1],\n",
       "         [2],\n",
       "         [0],\n",
       "         [0],\n",
       "         [8],\n",
       "         [6],\n",
       "         [1],\n",
       "         [6],\n",
       "         [3],\n",
       "         [8],\n",
       "         [5],\n",
       "         [0],\n",
       "         [9],\n",
       "         [1],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [0],\n",
       "         [5],\n",
       "         [2],\n",
       "         [6],\n",
       "         [1],\n",
       "         [5],\n",
       "         [9],\n",
       "         [0],\n",
       "         [8],\n",
       "         [8],\n",
       "         [1],\n",
       "         [4],\n",
       "         [9],\n",
       "         [4],\n",
       "         [4],\n",
       "         [1],\n",
       "         [0],\n",
       "         [7],\n",
       "         [3],\n",
       "         [9],\n",
       "         [1],\n",
       "         [0],\n",
       "         [2],\n",
       "         [3],\n",
       "         [1],\n",
       "         [5],\n",
       "         [2],\n",
       "         [6],\n",
       "         [9],\n",
       "         [2],\n",
       "         [3],\n",
       "         [0],\n",
       "         [7],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [0],\n",
       "         [9],\n",
       "         [3],\n",
       "         [8],\n",
       "         [3],\n",
       "         [4],\n",
       "         [2],\n",
       "         [2],\n",
       "         [1],\n",
       "         [9],\n",
       "         [0],\n",
       "         [2],\n",
       "         [8],\n",
       "         [6],\n",
       "         [6],\n",
       "         [0],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [1],\n",
       "         [2],\n",
       "         [0],\n",
       "         [8],\n",
       "         [9],\n",
       "         [4],\n",
       "         [1],\n",
       "         [7],\n",
       "         [2],\n",
       "         [6],\n",
       "         [1],\n",
       "         [3],\n",
       "         [3],\n",
       "         [0],\n",
       "         [1],\n",
       "         [9],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [8],\n",
       "         [2],\n",
       "         [6],\n",
       "         [2],\n",
       "         [9],\n",
       "         [7],\n",
       "         [7],\n",
       "         [7],\n",
       "         [9],\n",
       "         [8],\n",
       "         [9],\n",
       "         [4],\n",
       "         [4],\n",
       "         [7],\n",
       "         [1],\n",
       "         [0],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [9],\n",
       "         [8],\n",
       "         [3],\n",
       "         [6],\n",
       "         [8],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [2],\n",
       "         [6],\n",
       "         [7],\n",
       "         [3],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [2],\n",
       "         [5],\n",
       "         [1],\n",
       "         [2],\n",
       "         [9],\n",
       "         [2],\n",
       "         [2],\n",
       "         [1],\n",
       "         [6],\n",
       "         [3],\n",
       "         [9],\n",
       "         [1],\n",
       "         [1],\n",
       "         [5]], dtype=uint8)], [array([[158, 159, 165, ..., 124, 129, 110],\n",
       "         [235, 231, 232, ..., 178, 191, 199],\n",
       "         [158, 158, 139, ...,   8,   3,   7],\n",
       "         ..., \n",
       "         [ 20,  19,  15, ...,  50,  53,  47],\n",
       "         [ 25,  15,  23, ...,  80,  81,  80],\n",
       "         [ 73,  98,  99, ...,  94,  58,  26]], dtype=uint8), array([[3],\n",
       "         [8],\n",
       "         [8],\n",
       "         ..., \n",
       "         [5],\n",
       "         [1],\n",
       "         [7]], dtype=uint8)]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data_cifar\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3b import test_mlp\n",
    "load_data_cifar(theano_shared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data_cifar\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3b import test_mlp\n",
    "load_data_cifar(theano_shared=False)[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "Yo man\n",
      "... training\n",
      "print(validation_frequency) = 1800\n",
      "training @ iter =  0\n",
      "training @ iter =  100\n",
      "training @ iter =  200\n",
      "training @ iter =  300\n",
      "training @ iter =  400\n",
      "training @ iter =  500\n",
      "training @ iter =  600\n",
      "training @ iter =  700\n",
      "training @ iter =  800\n",
      "training @ iter =  900\n",
      "training @ iter =  1000\n",
      "training @ iter =  1100\n",
      "training @ iter =  1200\n",
      "training @ iter =  1300\n",
      "training @ iter =  1400\n",
      "training @ iter =  1500\n",
      "training @ iter =  1600\n",
      "training @ iter =  1700\n",
      "epoch 1, minibatch 1800/1800, validation error 89.925000 %\n",
      "     epoch 1, minibatch 1800/1800, test error of best model 90.000000 %\n",
      "training @ iter =  1800\n",
      "training @ iter =  1900\n",
      "training @ iter =  2000\n",
      "training @ iter =  2100\n",
      "training @ iter =  2200\n",
      "training @ iter =  2300\n",
      "training @ iter =  2400\n",
      "training @ iter =  2500\n",
      "training @ iter =  2600\n",
      "training @ iter =  2700\n",
      "training @ iter =  2800\n",
      "training @ iter =  2900\n",
      "training @ iter =  3000\n",
      "training @ iter =  3100\n",
      "training @ iter =  3200\n",
      "training @ iter =  3300\n",
      "training @ iter =  3400\n",
      "training @ iter =  3500\n",
      "epoch 2, minibatch 1800/1800, validation error 89.925000 %\n",
      "training @ iter =  3600\n",
      "training @ iter =  3700\n",
      "training @ iter =  3800\n",
      "training @ iter =  3900\n",
      "training @ iter =  4000\n",
      "training @ iter =  4100\n",
      "training @ iter =  4200\n",
      "training @ iter =  4300\n",
      "training @ iter =  4400\n",
      "training @ iter =  4500\n",
      "training @ iter =  4600\n",
      "training @ iter =  4700\n",
      "training @ iter =  4800\n",
      "training @ iter =  4900\n",
      "training @ iter =  5000\n",
      "training @ iter =  5100\n",
      "training @ iter =  5200\n",
      "training @ iter =  5300\n",
      "epoch 3, minibatch 1800/1800, validation error 89.925000 %\n",
      "training @ iter =  5400\n",
      "training @ iter =  5500\n",
      "training @ iter =  5600\n",
      "training @ iter =  5700\n",
      "training @ iter =  5800\n",
      "training @ iter =  5900\n",
      "training @ iter =  6000\n",
      "training @ iter =  6100\n",
      "training @ iter =  6200\n",
      "training @ iter =  6300\n",
      "training @ iter =  6400\n",
      "training @ iter =  6500\n",
      "training @ iter =  6600\n",
      "training @ iter =  6700\n",
      "training @ iter =  6800\n",
      "training @ iter =  6900\n",
      "training @ iter =  7000\n",
      "training @ iter =  7100\n",
      "epoch 4, minibatch 1800/1800, validation error 89.925000 %\n",
      "training @ iter =  7200\n",
      "training @ iter =  7300\n",
      "training @ iter =  7400\n",
      "training @ iter =  7500\n",
      "training @ iter =  7600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b4c03db97b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3bcifar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_lenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m test_lenet(learning_rate=0.1, n_epochs=100, nkerns=[16,32],\n\u001b[1;32m---> 11\u001b[1;33m             batch_size=20, verbose=True, fileName = 'predictions')\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3bcifar.pyc\u001b[0m in \u001b[0;36mtest_lenet\u001b[1;34m(learning_rate, n_epochs, nkerns, batch_size, verbose, fileName)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     predictions = train_nn(train_model, validate_model, test_model, getPredictedValue,\n\u001b[1;32m--> 224\u001b[1;33m         n_train_batches, n_valid_batches, n_test_batches, n_epochs, verbose)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/dropconnect/src/hw3_nn.pyc\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(train_model, validate_model, test_model, getPredictedValue, n_train_batches, n_valid_batches, n_test_batches, n_epochs, verbose)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training @ iter = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalidation_frequency\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/tensor/raw_random.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, out_)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mrout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data, load_data_cifar\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3bcifar import test_lenet\n",
    "test_lenet(learning_rate=0.1, n_epochs=100, nkerns=[16,32],\n",
    "            batch_size=20, verbose=True, fileName = 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = load_data_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x, train_set_y = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{Cast{int32}}.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "Yo Man\n",
      "... training\n",
      "print(validation_frequency) = 2500\n",
      "training @ iter =  0\n",
      "training @ iter =  100\n",
      "training @ iter =  200\n",
      "training @ iter =  300\n",
      "training @ iter =  400\n",
      "training @ iter =  500\n",
      "training @ iter =  600\n",
      "training @ iter =  700\n",
      "training @ iter =  800\n",
      "training @ iter =  900\n",
      "training @ iter =  1000\n",
      "training @ iter =  1100\n",
      "training @ iter =  1200\n",
      "training @ iter =  1300\n",
      "training @ iter =  1400\n",
      "training @ iter =  1500\n",
      "training @ iter =  1600\n",
      "training @ iter =  1700\n",
      "training @ iter =  1800\n",
      "training @ iter =  1900\n",
      "training @ iter =  2000\n",
      "training @ iter =  2100\n",
      "training @ iter =  2200\n",
      "training @ iter =  2300\n",
      "training @ iter =  2400\n",
      "epoch 1, minibatch 2500/2500, validation error 31.300000 %\n",
      "     epoch 1, minibatch 2500/2500, test error of best model 31.740000 %\n",
      "training @ iter =  2500\n",
      "training @ iter =  2600\n",
      "training @ iter =  2700\n",
      "training @ iter =  2800\n",
      "training @ iter =  2900\n",
      "training @ iter =  3000\n",
      "training @ iter =  3100\n",
      "training @ iter =  3200\n",
      "training @ iter =  3300\n",
      "training @ iter =  3400\n",
      "training @ iter =  3500\n",
      "training @ iter =  3600\n",
      "training @ iter =  3700\n",
      "training @ iter =  3800\n",
      "training @ iter =  3900\n",
      "training @ iter =  4000\n",
      "training @ iter =  4100\n",
      "training @ iter =  4200\n",
      "training @ iter =  4300\n",
      "training @ iter =  4400\n",
      "training @ iter =  4500\n",
      "training @ iter =  4600\n",
      "training @ iter =  4700\n",
      "training @ iter =  4800\n",
      "training @ iter =  4900\n",
      "epoch 2, minibatch 2500/2500, validation error 13.660000 %\n",
      "     epoch 2, minibatch 2500/2500, test error of best model 13.830000 %\n",
      "training @ iter =  5000\n",
      "training @ iter =  5100\n",
      "training @ iter =  5200\n",
      "training @ iter =  5300\n",
      "training @ iter =  5400\n",
      "training @ iter =  5500\n",
      "training @ iter =  5600\n",
      "training @ iter =  5700\n",
      "training @ iter =  5800\n",
      "training @ iter =  5900\n",
      "training @ iter =  6000\n",
      "training @ iter =  6100\n",
      "training @ iter =  6200\n",
      "training @ iter =  6300\n",
      "training @ iter =  6400\n",
      "training @ iter =  6500\n",
      "training @ iter =  6600\n",
      "training @ iter =  6700\n",
      "training @ iter =  6800\n",
      "training @ iter =  6900\n",
      "training @ iter =  7000\n",
      "training @ iter =  7100\n",
      "training @ iter =  7200\n",
      "training @ iter =  7300\n",
      "training @ iter =  7400\n",
      "epoch 3, minibatch 2500/2500, validation error 8.650000 %\n",
      "     epoch 3, minibatch 2500/2500, test error of best model 8.560000 %\n",
      "training @ iter =  7500\n",
      "training @ iter =  7600\n",
      "training @ iter =  7700\n",
      "training @ iter =  7800\n",
      "training @ iter =  7900\n",
      "training @ iter =  8000\n",
      "training @ iter =  8100\n",
      "training @ iter =  8200\n",
      "training @ iter =  8300\n",
      "training @ iter =  8400\n",
      "training @ iter =  8500\n",
      "training @ iter =  8600\n",
      "training @ iter =  8700\n",
      "training @ iter =  8800\n",
      "training @ iter =  8900\n",
      "training @ iter =  9000\n",
      "training @ iter =  9100\n",
      "training @ iter =  9200\n",
      "training @ iter =  9300\n",
      "training @ iter =  9400\n",
      "training @ iter =  9500\n",
      "training @ iter =  9600\n",
      "training @ iter =  9700\n",
      "training @ iter =  9800\n",
      "training @ iter =  9900\n",
      "epoch 4, minibatch 2500/2500, validation error 6.950000 %\n",
      "     epoch 4, minibatch 2500/2500, test error of best model 6.930000 %\n",
      "training @ iter =  10000\n",
      "training @ iter =  10100\n",
      "training @ iter =  10200\n",
      "training @ iter =  10300\n",
      "training @ iter =  10400\n",
      "training @ iter =  10500\n",
      "training @ iter =  10600\n",
      "training @ iter =  10700\n",
      "training @ iter =  10800\n",
      "training @ iter =  10900\n",
      "training @ iter =  11000\n",
      "training @ iter =  11100\n",
      "training @ iter =  11200\n",
      "training @ iter =  11300\n",
      "training @ iter =  11400\n",
      "training @ iter =  11500\n",
      "training @ iter =  11600\n",
      "training @ iter =  11700\n",
      "training @ iter =  11800\n",
      "training @ iter =  11900\n",
      "training @ iter =  12000\n",
      "training @ iter =  12100\n",
      "training @ iter =  12200\n",
      "training @ iter =  12300\n",
      "training @ iter =  12400\n",
      "epoch 5, minibatch 2500/2500, validation error 5.530000 %\n",
      "     epoch 5, minibatch 2500/2500, test error of best model 5.500000 %\n",
      "training @ iter =  12500\n",
      "training @ iter =  12600\n",
      "training @ iter =  12700\n",
      "training @ iter =  12800\n",
      "training @ iter =  12900\n",
      "training @ iter =  13000\n",
      "training @ iter =  13100\n",
      "training @ iter =  13200\n",
      "training @ iter =  13300\n",
      "training @ iter =  13400\n",
      "training @ iter =  13500\n",
      "training @ iter =  13600\n",
      "training @ iter =  13700\n",
      "training @ iter =  13800\n",
      "training @ iter =  13900\n",
      "training @ iter =  14000\n",
      "training @ iter =  14100\n",
      "training @ iter =  14200\n",
      "training @ iter =  14300\n",
      "training @ iter =  14400\n",
      "training @ iter =  14500\n",
      "training @ iter =  14600\n",
      "training @ iter =  14700\n",
      "training @ iter =  14800\n",
      "training @ iter =  14900\n",
      "epoch 6, minibatch 2500/2500, validation error 5.340000 %\n",
      "     epoch 6, minibatch 2500/2500, test error of best model 5.020000 %\n",
      "training @ iter =  15000\n",
      "training @ iter =  15100\n",
      "training @ iter =  15200\n",
      "training @ iter =  15300\n",
      "training @ iter =  15400\n",
      "training @ iter =  15500\n",
      "training @ iter =  15600\n",
      "training @ iter =  15700\n",
      "training @ iter =  15800\n",
      "training @ iter =  15900\n",
      "training @ iter =  16000\n",
      "training @ iter =  16100\n",
      "training @ iter =  16200\n",
      "training @ iter =  16300\n",
      "training @ iter =  16400\n",
      "training @ iter =  16500\n",
      "training @ iter =  16600\n",
      "training @ iter =  16700\n",
      "training @ iter =  16800\n",
      "training @ iter =  16900\n",
      "training @ iter =  17000\n",
      "training @ iter =  17100\n",
      "training @ iter =  17200\n",
      "training @ iter =  17300\n",
      "training @ iter =  17400\n",
      "epoch 7, minibatch 2500/2500, validation error 4.380000 %\n",
      "     epoch 7, minibatch 2500/2500, test error of best model 4.460000 %\n",
      "training @ iter =  17500\n",
      "training @ iter =  17600\n",
      "training @ iter =  17700\n",
      "training @ iter =  17800\n",
      "training @ iter =  17900\n",
      "training @ iter =  18000\n",
      "training @ iter =  18100\n",
      "training @ iter =  18200\n",
      "training @ iter =  18300\n",
      "training @ iter =  18400\n",
      "training @ iter =  18500\n",
      "training @ iter =  18600\n",
      "training @ iter =  18700\n",
      "training @ iter =  18800\n",
      "training @ iter =  18900\n",
      "training @ iter =  19000\n",
      "training @ iter =  19100\n",
      "training @ iter =  19200\n",
      "training @ iter =  19300\n",
      "training @ iter =  19400\n",
      "training @ iter =  19500\n",
      "training @ iter =  19600\n",
      "training @ iter =  19700\n",
      "training @ iter =  19800\n",
      "training @ iter =  19900\n",
      "epoch 8, minibatch 2500/2500, validation error 4.510000 %\n",
      "training @ iter =  20000\n",
      "training @ iter =  20100\n",
      "training @ iter =  20200\n",
      "training @ iter =  20300\n",
      "training @ iter =  20400\n",
      "training @ iter =  20500\n",
      "training @ iter =  20600\n",
      "training @ iter =  20700\n",
      "training @ iter =  20800\n",
      "training @ iter =  20900\n",
      "training @ iter =  21000\n",
      "training @ iter =  21100\n",
      "training @ iter =  21200\n",
      "training @ iter =  21300\n",
      "training @ iter =  21400\n",
      "training @ iter =  21500\n",
      "training @ iter =  21600\n",
      "training @ iter =  21700\n",
      "training @ iter =  21800\n",
      "training @ iter =  21900\n",
      "training @ iter =  22000\n",
      "training @ iter =  22100\n",
      "training @ iter =  22200\n",
      "training @ iter =  22300\n",
      "training @ iter =  22400\n",
      "epoch 9, minibatch 2500/2500, validation error 3.960000 %\n",
      "     epoch 9, minibatch 2500/2500, test error of best model 4.200000 %\n",
      "training @ iter =  22500\n",
      "training @ iter =  22600\n",
      "training @ iter =  22700\n",
      "training @ iter =  22800\n",
      "training @ iter =  22900\n",
      "training @ iter =  23000\n",
      "training @ iter =  23100\n",
      "training @ iter =  23200\n",
      "training @ iter =  23300\n",
      "training @ iter =  23400\n",
      "training @ iter =  23500\n",
      "training @ iter =  23600\n",
      "training @ iter =  23700\n",
      "training @ iter =  23800\n",
      "training @ iter =  23900\n",
      "training @ iter =  24000\n",
      "training @ iter =  24100\n",
      "training @ iter =  24200\n",
      "training @ iter =  24300\n",
      "training @ iter =  24400\n",
      "training @ iter =  24500\n",
      "training @ iter =  24600\n",
      "training @ iter =  24700\n",
      "training @ iter =  24800\n",
      "training @ iter =  24900\n",
      "epoch 10, minibatch 2500/2500, validation error 4.210000 %\n",
      "training @ iter =  25000\n",
      "training @ iter =  25100\n",
      "training @ iter =  25200\n",
      "training @ iter =  25300\n",
      "training @ iter =  25400\n",
      "training @ iter =  25500\n",
      "training @ iter =  25600\n",
      "training @ iter =  25700\n",
      "training @ iter =  25800\n",
      "training @ iter =  25900\n",
      "training @ iter =  26000\n",
      "training @ iter =  26100\n",
      "training @ iter =  26200\n",
      "training @ iter =  26300\n",
      "training @ iter =  26400\n",
      "training @ iter =  26500\n",
      "training @ iter =  26600\n",
      "training @ iter =  26700\n",
      "training @ iter =  26800\n",
      "training @ iter =  26900\n",
      "training @ iter =  27000\n",
      "training @ iter =  27100\n",
      "training @ iter =  27200\n",
      "training @ iter =  27300\n",
      "training @ iter =  27400\n",
      "epoch 11, minibatch 2500/2500, validation error 4.170000 %\n",
      "training @ iter =  27500\n",
      "training @ iter =  27600\n",
      "training @ iter =  27700\n",
      "training @ iter =  27800\n",
      "training @ iter =  27900\n",
      "training @ iter =  28000\n",
      "training @ iter =  28100\n",
      "training @ iter =  28200\n",
      "training @ iter =  28300\n",
      "training @ iter =  28400\n",
      "training @ iter =  28500\n",
      "training @ iter =  28600\n",
      "training @ iter =  28700\n",
      "training @ iter =  28800\n",
      "training @ iter =  28900\n",
      "training @ iter =  29000\n",
      "training @ iter =  29100\n",
      "training @ iter =  29200\n",
      "training @ iter =  29300\n",
      "training @ iter =  29400\n",
      "training @ iter =  29500\n",
      "training @ iter =  29600\n",
      "training @ iter =  29700\n",
      "training @ iter =  29800\n",
      "training @ iter =  29900\n",
      "epoch 12, minibatch 2500/2500, validation error 3.620000 %\n",
      "     epoch 12, minibatch 2500/2500, test error of best model 3.570000 %\n",
      "training @ iter =  30000\n",
      "training @ iter =  30100\n",
      "training @ iter =  30200\n",
      "training @ iter =  30300\n",
      "training @ iter =  30400\n",
      "training @ iter =  30500\n",
      "training @ iter =  30600\n",
      "training @ iter =  30700\n",
      "training @ iter =  30800\n",
      "training @ iter =  30900\n",
      "training @ iter =  31000\n",
      "training @ iter =  31100\n",
      "training @ iter =  31200\n",
      "training @ iter =  31300\n",
      "training @ iter =  31400\n",
      "training @ iter =  31500\n",
      "training @ iter =  31600\n",
      "training @ iter =  31700\n",
      "training @ iter =  31800\n",
      "training @ iter =  31900\n",
      "training @ iter =  32000\n",
      "training @ iter =  32100\n",
      "training @ iter =  32200\n",
      "training @ iter =  32300\n",
      "training @ iter =  32400\n",
      "epoch 13, minibatch 2500/2500, validation error 4.000000 %\n",
      "training @ iter =  32500\n",
      "training @ iter =  32600\n",
      "training @ iter =  32700\n",
      "training @ iter =  32800\n",
      "training @ iter =  32900\n",
      "training @ iter =  33000\n",
      "training @ iter =  33100\n",
      "training @ iter =  33200\n",
      "training @ iter =  33300\n",
      "training @ iter =  33400\n",
      "training @ iter =  33500\n",
      "training @ iter =  33600\n",
      "training @ iter =  33700\n",
      "training @ iter =  33800\n",
      "training @ iter =  33900\n",
      "training @ iter =  34000\n",
      "training @ iter =  34100\n",
      "training @ iter =  34200\n",
      "training @ iter =  34300\n",
      "training @ iter =  34400\n",
      "training @ iter =  34500\n",
      "training @ iter =  34600\n",
      "training @ iter =  34700\n",
      "training @ iter =  34800\n",
      "training @ iter =  34900\n",
      "epoch 14, minibatch 2500/2500, validation error 3.880000 %\n",
      "training @ iter =  35000\n",
      "training @ iter =  35100\n",
      "training @ iter =  35200\n",
      "training @ iter =  35300\n",
      "training @ iter =  35400\n",
      "training @ iter =  35500\n",
      "training @ iter =  35600\n",
      "training @ iter =  35700\n",
      "training @ iter =  35800\n",
      "training @ iter =  35900\n",
      "training @ iter =  36000\n",
      "training @ iter =  36100\n",
      "training @ iter =  36200\n",
      "training @ iter =  36300\n",
      "training @ iter =  36400\n",
      "training @ iter =  36500\n",
      "training @ iter =  36600\n",
      "training @ iter =  36700\n",
      "training @ iter =  36800\n",
      "training @ iter =  36900\n",
      "training @ iter =  37000\n",
      "training @ iter =  37100\n",
      "training @ iter =  37200\n",
      "training @ iter =  37300\n",
      "training @ iter =  37400\n",
      "epoch 15, minibatch 2500/2500, validation error 3.540000 %\n",
      "     epoch 15, minibatch 2500/2500, test error of best model 3.550000 %\n",
      "training @ iter =  37500\n",
      "training @ iter =  37600\n",
      "training @ iter =  37700\n",
      "training @ iter =  37800\n",
      "training @ iter =  37900\n",
      "training @ iter =  38000\n",
      "training @ iter =  38100\n",
      "training @ iter =  38200\n",
      "training @ iter =  38300\n",
      "training @ iter =  38400\n",
      "training @ iter =  38500\n",
      "training @ iter =  38600\n",
      "training @ iter =  38700\n",
      "training @ iter =  38800\n",
      "training @ iter =  38900\n",
      "training @ iter =  39000\n",
      "training @ iter =  39100\n",
      "training @ iter =  39200\n",
      "training @ iter =  39300\n",
      "training @ iter =  39400\n",
      "training @ iter =  39500\n",
      "training @ iter =  39600\n",
      "training @ iter =  39700\n",
      "training @ iter =  39800\n",
      "training @ iter =  39900\n",
      "epoch 16, minibatch 2500/2500, validation error 3.320000 %\n",
      "     epoch 16, minibatch 2500/2500, test error of best model 3.370000 %\n",
      "training @ iter =  40000\n",
      "training @ iter =  40100\n",
      "training @ iter =  40200\n",
      "training @ iter =  40300\n",
      "training @ iter =  40400\n",
      "training @ iter =  40500\n",
      "training @ iter =  40600\n",
      "training @ iter =  40700\n",
      "training @ iter =  40800\n",
      "training @ iter =  40900\n",
      "training @ iter =  41000\n",
      "training @ iter =  41100\n",
      "training @ iter =  41200\n",
      "training @ iter =  41300\n",
      "training @ iter =  41400\n",
      "training @ iter =  41500\n",
      "training @ iter =  41600\n",
      "training @ iter =  41700\n",
      "training @ iter =  41800\n",
      "training @ iter =  41900\n",
      "training @ iter =  42000\n",
      "training @ iter =  42100\n",
      "training @ iter =  42200\n",
      "training @ iter =  42300\n",
      "training @ iter =  42400\n",
      "epoch 17, minibatch 2500/2500, validation error 3.240000 %\n",
      "     epoch 17, minibatch 2500/2500, test error of best model 3.310000 %\n",
      "training @ iter =  42500\n",
      "training @ iter =  42600\n",
      "training @ iter =  42700\n",
      "training @ iter =  42800\n",
      "training @ iter =  42900\n",
      "training @ iter =  43000\n",
      "training @ iter =  43100\n",
      "training @ iter =  43200\n",
      "training @ iter =  43300\n",
      "training @ iter =  43400\n",
      "training @ iter =  43500\n",
      "training @ iter =  43600\n",
      "training @ iter =  43700\n",
      "training @ iter =  43800\n",
      "training @ iter =  43900\n",
      "training @ iter =  44000\n",
      "training @ iter =  44100\n",
      "training @ iter =  44200\n",
      "training @ iter =  44300\n",
      "training @ iter =  44400\n",
      "training @ iter =  44500\n",
      "training @ iter =  44600\n",
      "training @ iter =  44700\n",
      "training @ iter =  44800\n",
      "training @ iter =  44900\n",
      "epoch 18, minibatch 2500/2500, validation error 3.450000 %\n",
      "training @ iter =  45000\n",
      "training @ iter =  45100\n",
      "training @ iter =  45200\n",
      "training @ iter =  45300\n",
      "training @ iter =  45400\n",
      "training @ iter =  45500\n",
      "training @ iter =  45600\n",
      "training @ iter =  45700\n",
      "training @ iter =  45800\n",
      "training @ iter =  45900\n",
      "training @ iter =  46000\n",
      "training @ iter =  46100\n",
      "training @ iter =  46200\n",
      "training @ iter =  46300\n",
      "training @ iter =  46400\n",
      "training @ iter =  46500\n",
      "training @ iter =  46600\n",
      "training @ iter =  46700\n",
      "training @ iter =  46800\n",
      "training @ iter =  46900\n",
      "training @ iter =  47000\n",
      "training @ iter =  47100\n",
      "training @ iter =  47200\n",
      "training @ iter =  47300\n",
      "training @ iter =  47400\n",
      "epoch 19, minibatch 2500/2500, validation error 3.650000 %\n",
      "training @ iter =  47500\n",
      "training @ iter =  47600\n",
      "training @ iter =  47700\n",
      "training @ iter =  47800\n",
      "training @ iter =  47900\n",
      "training @ iter =  48000\n",
      "training @ iter =  48100\n",
      "training @ iter =  48200\n",
      "training @ iter =  48300\n",
      "training @ iter =  48400\n",
      "training @ iter =  48500\n",
      "training @ iter =  48600\n",
      "training @ iter =  48700\n",
      "training @ iter =  48800\n",
      "training @ iter =  48900\n",
      "training @ iter =  49000\n",
      "training @ iter =  49100\n",
      "training @ iter =  49200\n",
      "training @ iter =  49300\n",
      "training @ iter =  49400\n",
      "training @ iter =  49500\n",
      "training @ iter =  49600\n",
      "training @ iter =  49700\n",
      "training @ iter =  49800\n",
      "training @ iter =  49900\n",
      "epoch 20, minibatch 2500/2500, validation error 3.180000 %\n",
      "     epoch 20, minibatch 2500/2500, test error of best model 3.280000 %\n",
      "training @ iter =  50000\n",
      "training @ iter =  50100\n",
      "training @ iter =  50200\n",
      "training @ iter =  50300\n",
      "training @ iter =  50400\n",
      "training @ iter =  50500\n",
      "training @ iter =  50600\n",
      "training @ iter =  50700\n",
      "training @ iter =  50800\n",
      "training @ iter =  50900\n",
      "training @ iter =  51000\n",
      "training @ iter =  51100\n",
      "training @ iter =  51200\n",
      "training @ iter =  51300\n",
      "training @ iter =  51400\n",
      "training @ iter =  51500\n",
      "training @ iter =  51600\n",
      "training @ iter =  51700\n",
      "training @ iter =  51800\n",
      "training @ iter =  51900\n",
      "training @ iter =  52000\n",
      "training @ iter =  52100\n",
      "training @ iter =  52200\n",
      "training @ iter =  52300\n",
      "training @ iter =  52400\n",
      "epoch 21, minibatch 2500/2500, validation error 3.240000 %\n",
      "training @ iter =  52500\n",
      "training @ iter =  52600\n",
      "training @ iter =  52700\n",
      "training @ iter =  52800\n",
      "training @ iter =  52900\n",
      "training @ iter =  53000\n",
      "training @ iter =  53100\n",
      "training @ iter =  53200\n",
      "training @ iter =  53300\n",
      "training @ iter =  53400\n",
      "training @ iter =  53500\n",
      "training @ iter =  53600\n",
      "training @ iter =  53700\n",
      "training @ iter =  53800\n",
      "training @ iter =  53900\n",
      "training @ iter =  54000\n",
      "training @ iter =  54100\n",
      "training @ iter =  54200\n",
      "training @ iter =  54300\n",
      "training @ iter =  54400\n",
      "training @ iter =  54500\n",
      "training @ iter =  54600\n",
      "training @ iter =  54700\n",
      "training @ iter =  54800\n",
      "training @ iter =  54900\n",
      "epoch 22, minibatch 2500/2500, validation error 3.280000 %\n",
      "training @ iter =  55000\n",
      "training @ iter =  55100\n",
      "training @ iter =  55200\n",
      "training @ iter =  55300\n",
      "training @ iter =  55400\n",
      "training @ iter =  55500\n",
      "training @ iter =  55600\n",
      "training @ iter =  55700\n",
      "training @ iter =  55800\n",
      "training @ iter =  55900\n",
      "training @ iter =  56000\n",
      "training @ iter =  56100\n",
      "training @ iter =  56200\n",
      "training @ iter =  56300\n",
      "training @ iter =  56400\n",
      "training @ iter =  56500\n",
      "training @ iter =  56600\n",
      "training @ iter =  56700\n",
      "training @ iter =  56800\n",
      "training @ iter =  56900\n",
      "training @ iter =  57000\n",
      "training @ iter =  57100\n",
      "training @ iter =  57200\n",
      "training @ iter =  57300\n",
      "training @ iter =  57400\n",
      "epoch 23, minibatch 2500/2500, validation error 2.950000 %\n",
      "     epoch 23, minibatch 2500/2500, test error of best model 3.190000 %\n",
      "training @ iter =  57500\n",
      "training @ iter =  57600\n",
      "training @ iter =  57700\n",
      "training @ iter =  57800\n",
      "training @ iter =  57900\n",
      "training @ iter =  58000\n",
      "training @ iter =  58100\n",
      "training @ iter =  58200\n",
      "training @ iter =  58300\n",
      "training @ iter =  58400\n",
      "training @ iter =  58500\n",
      "training @ iter =  58600\n",
      "training @ iter =  58700\n",
      "training @ iter =  58800\n",
      "training @ iter =  58900\n",
      "training @ iter =  59000\n",
      "training @ iter =  59100\n",
      "training @ iter =  59200\n",
      "training @ iter =  59300\n",
      "training @ iter =  59400\n",
      "training @ iter =  59500\n",
      "training @ iter =  59600\n",
      "training @ iter =  59700\n",
      "training @ iter =  59800\n",
      "training @ iter =  59900\n",
      "epoch 24, minibatch 2500/2500, validation error 2.850000 %\n",
      "     epoch 24, minibatch 2500/2500, test error of best model 2.990000 %\n",
      "training @ iter =  60000\n",
      "training @ iter =  60100\n",
      "training @ iter =  60200\n",
      "training @ iter =  60300\n",
      "training @ iter =  60400\n",
      "training @ iter =  60500\n",
      "training @ iter =  60600\n",
      "training @ iter =  60700\n",
      "training @ iter =  60800\n",
      "training @ iter =  60900\n",
      "training @ iter =  61000\n",
      "training @ iter =  61100\n",
      "training @ iter =  61200\n",
      "training @ iter =  61300\n",
      "training @ iter =  61400\n",
      "training @ iter =  61500\n",
      "training @ iter =  61600\n",
      "training @ iter =  61700\n",
      "training @ iter =  61800\n",
      "training @ iter =  61900\n",
      "training @ iter =  62000\n",
      "training @ iter =  62100\n",
      "training @ iter =  62200\n",
      "training @ iter =  62300\n",
      "training @ iter =  62400\n",
      "epoch 25, minibatch 2500/2500, validation error 3.160000 %\n",
      "Validation error not improved for 10 epochs, changing the learning rate to 0.005\n",
      "training @ iter =  62500\n",
      "training @ iter =  62600\n",
      "training @ iter =  62700\n",
      "training @ iter =  62800\n",
      "training @ iter =  62900\n",
      "training @ iter =  63000\n",
      "training @ iter =  63100\n",
      "training @ iter =  63200\n",
      "training @ iter =  63300\n",
      "training @ iter =  63400\n",
      "training @ iter =  63500\n",
      "training @ iter =  63600\n",
      "training @ iter =  63700\n",
      "training @ iter =  63800\n",
      "training @ iter =  63900\n",
      "training @ iter =  64000\n",
      "training @ iter =  64100\n",
      "training @ iter =  64200\n",
      "training @ iter =  64300\n",
      "training @ iter =  64400\n",
      "training @ iter =  64500\n",
      "training @ iter =  64600\n",
      "training @ iter =  64700\n",
      "training @ iter =  64800\n",
      "training @ iter =  64900\n",
      "epoch 26, minibatch 2500/2500, validation error 2.980000 %\n",
      "training @ iter =  65000\n",
      "training @ iter =  65100\n",
      "training @ iter =  65200\n",
      "training @ iter =  65300\n",
      "training @ iter =  65400\n",
      "training @ iter =  65500\n",
      "training @ iter =  65600\n",
      "training @ iter =  65700\n",
      "training @ iter =  65800\n",
      "training @ iter =  65900\n",
      "training @ iter =  66000\n",
      "training @ iter =  66100\n",
      "training @ iter =  66200\n",
      "training @ iter =  66300\n",
      "training @ iter =  66400\n",
      "training @ iter =  66500\n",
      "training @ iter =  66600\n",
      "training @ iter =  66700\n",
      "training @ iter =  66800\n",
      "training @ iter =  66900\n",
      "training @ iter =  67000\n",
      "training @ iter =  67100\n",
      "training @ iter =  67200\n",
      "training @ iter =  67300\n",
      "training @ iter =  67400\n",
      "epoch 27, minibatch 2500/2500, validation error 3.130000 %\n",
      "training @ iter =  67500\n",
      "training @ iter =  67600\n",
      "training @ iter =  67700\n",
      "training @ iter =  67800\n",
      "training @ iter =  67900\n",
      "training @ iter =  68000\n",
      "training @ iter =  68100\n",
      "training @ iter =  68200\n",
      "training @ iter =  68300\n",
      "training @ iter =  68400\n",
      "training @ iter =  68500\n",
      "training @ iter =  68600\n",
      "training @ iter =  68700\n",
      "training @ iter =  68800\n",
      "training @ iter =  68900\n",
      "training @ iter =  69000\n",
      "training @ iter =  69100\n",
      "training @ iter =  69200\n",
      "training @ iter =  69300\n",
      "training @ iter =  69400\n",
      "training @ iter =  69500\n",
      "training @ iter =  69600\n",
      "training @ iter =  69700\n",
      "training @ iter =  69800\n",
      "training @ iter =  69900\n",
      "epoch 28, minibatch 2500/2500, validation error 3.170000 %\n",
      "training @ iter =  70000\n",
      "training @ iter =  70100\n",
      "training @ iter =  70200\n",
      "training @ iter =  70300\n",
      "training @ iter =  70400\n",
      "training @ iter =  70500\n",
      "training @ iter =  70600\n",
      "training @ iter =  70700\n",
      "training @ iter =  70800\n",
      "training @ iter =  70900\n",
      "training @ iter =  71000\n",
      "training @ iter =  71100\n",
      "training @ iter =  71200\n",
      "training @ iter =  71300\n",
      "training @ iter =  71400\n",
      "training @ iter =  71500\n",
      "training @ iter =  71600\n",
      "training @ iter =  71700\n",
      "training @ iter =  71800\n",
      "training @ iter =  71900\n",
      "training @ iter =  72000\n",
      "training @ iter =  72100\n",
      "training @ iter =  72200\n",
      "training @ iter =  72300\n",
      "training @ iter =  72400\n",
      "epoch 29, minibatch 2500/2500, validation error 3.030000 %\n",
      "training @ iter =  72500\n",
      "training @ iter =  72600\n",
      "training @ iter =  72700\n",
      "training @ iter =  72800\n",
      "training @ iter =  72900\n",
      "training @ iter =  73000\n",
      "training @ iter =  73100\n",
      "training @ iter =  73200\n",
      "training @ iter =  73300\n",
      "training @ iter =  73400\n",
      "training @ iter =  73500\n",
      "training @ iter =  73600\n",
      "training @ iter =  73700\n",
      "training @ iter =  73800\n",
      "training @ iter =  73900\n",
      "training @ iter =  74000\n",
      "training @ iter =  74100\n",
      "training @ iter =  74200\n",
      "training @ iter =  74300\n",
      "training @ iter =  74400\n",
      "training @ iter =  74500\n",
      "training @ iter =  74600\n",
      "training @ iter =  74700\n",
      "training @ iter =  74800\n",
      "training @ iter =  74900\n",
      "epoch 30, minibatch 2500/2500, validation error 2.900000 %\n",
      "training @ iter =  75000\n",
      "training @ iter =  75100\n",
      "training @ iter =  75200\n",
      "training @ iter =  75300\n",
      "training @ iter =  75400\n",
      "training @ iter =  75500\n",
      "training @ iter =  75600\n",
      "training @ iter =  75700\n",
      "training @ iter =  75800\n",
      "training @ iter =  75900\n",
      "training @ iter =  76000\n",
      "training @ iter =  76100\n",
      "training @ iter =  76200\n",
      "training @ iter =  76300\n",
      "training @ iter =  76400\n",
      "training @ iter =  76500\n",
      "training @ iter =  76600\n",
      "training @ iter =  76700\n",
      "training @ iter =  76800\n",
      "training @ iter =  76900\n",
      "training @ iter =  77000\n",
      "training @ iter =  77100\n",
      "training @ iter =  77200\n",
      "training @ iter =  77300\n",
      "training @ iter =  77400\n",
      "epoch 31, minibatch 2500/2500, validation error 2.900000 %\n",
      "training @ iter =  77500\n",
      "training @ iter =  77600\n",
      "training @ iter =  77700\n",
      "training @ iter =  77800\n",
      "training @ iter =  77900\n",
      "training @ iter =  78000\n",
      "training @ iter =  78100\n",
      "training @ iter =  78200\n",
      "training @ iter =  78300\n",
      "training @ iter =  78400\n",
      "training @ iter =  78500\n",
      "training @ iter =  78600\n",
      "training @ iter =  78700\n",
      "training @ iter =  78800\n",
      "training @ iter =  78900\n",
      "training @ iter =  79000\n",
      "training @ iter =  79100\n",
      "training @ iter =  79200\n",
      "training @ iter =  79300\n",
      "training @ iter =  79400\n",
      "training @ iter =  79500\n",
      "training @ iter =  79600\n",
      "training @ iter =  79700\n",
      "training @ iter =  79800\n",
      "training @ iter =  79900\n",
      "epoch 32, minibatch 2500/2500, validation error 3.010000 %\n",
      "training @ iter =  80000\n",
      "training @ iter =  80100\n",
      "training @ iter =  80200\n",
      "training @ iter =  80300\n",
      "training @ iter =  80400\n",
      "training @ iter =  80500\n",
      "training @ iter =  80600\n",
      "training @ iter =  80700\n",
      "training @ iter =  80800\n",
      "training @ iter =  80900\n",
      "training @ iter =  81000\n",
      "training @ iter =  81100\n",
      "training @ iter =  81200\n",
      "training @ iter =  81300\n",
      "training @ iter =  81400\n",
      "training @ iter =  81500\n",
      "training @ iter =  81600\n",
      "training @ iter =  81700\n",
      "training @ iter =  81800\n",
      "training @ iter =  81900\n",
      "training @ iter =  82000\n",
      "training @ iter =  82100\n",
      "training @ iter =  82200\n",
      "training @ iter =  82300\n",
      "training @ iter =  82400\n",
      "epoch 33, minibatch 2500/2500, validation error 3.040000 %\n",
      "training @ iter =  82500\n",
      "training @ iter =  82600\n",
      "training @ iter =  82700\n",
      "training @ iter =  82800\n",
      "training @ iter =  82900\n",
      "training @ iter =  83000\n",
      "training @ iter =  83100\n",
      "training @ iter =  83200\n",
      "training @ iter =  83300\n",
      "training @ iter =  83400\n",
      "training @ iter =  83500\n",
      "training @ iter =  83600\n",
      "training @ iter =  83700\n",
      "training @ iter =  83800\n",
      "training @ iter =  83900\n",
      "training @ iter =  84000\n",
      "training @ iter =  84100\n",
      "training @ iter =  84200\n",
      "training @ iter =  84300\n",
      "training @ iter =  84400\n",
      "training @ iter =  84500\n",
      "training @ iter =  84600\n",
      "training @ iter =  84700\n",
      "training @ iter =  84800\n",
      "training @ iter =  84900\n",
      "epoch 34, minibatch 2500/2500, validation error 2.910000 %\n",
      "training @ iter =  85000\n",
      "training @ iter =  85100\n",
      "training @ iter =  85200\n",
      "training @ iter =  85300\n",
      "training @ iter =  85400\n",
      "training @ iter =  85500\n",
      "training @ iter =  85600\n",
      "training @ iter =  85700\n",
      "training @ iter =  85800\n",
      "training @ iter =  85900\n",
      "training @ iter =  86000\n",
      "training @ iter =  86100\n",
      "training @ iter =  86200\n",
      "training @ iter =  86300\n",
      "training @ iter =  86400\n",
      "training @ iter =  86500\n",
      "training @ iter =  86600\n",
      "training @ iter =  86700\n",
      "training @ iter =  86800\n",
      "training @ iter =  86900\n",
      "training @ iter =  87000\n",
      "training @ iter =  87100\n",
      "training @ iter =  87200\n",
      "training @ iter =  87300\n",
      "training @ iter =  87400\n",
      "epoch 35, minibatch 2500/2500, validation error 3.170000 %\n",
      "Validation error not improved for 10 epochs, changing the learning rate to 0.0025\n",
      "training @ iter =  87500\n",
      "training @ iter =  87600\n",
      "training @ iter =  87700\n",
      "training @ iter =  87800\n",
      "training @ iter =  87900\n",
      "training @ iter =  88000\n",
      "training @ iter =  88100\n",
      "training @ iter =  88200\n",
      "training @ iter =  88300\n",
      "training @ iter =  88400\n",
      "training @ iter =  88500\n",
      "training @ iter =  88600\n",
      "training @ iter =  88700\n",
      "training @ iter =  88800\n",
      "training @ iter =  88900\n",
      "training @ iter =  89000\n",
      "training @ iter =  89100\n",
      "training @ iter =  89200\n",
      "training @ iter =  89300\n",
      "training @ iter =  89400\n",
      "training @ iter =  89500\n",
      "training @ iter =  89600\n",
      "training @ iter =  89700\n",
      "training @ iter =  89800\n",
      "training @ iter =  89900\n",
      "epoch 36, minibatch 2500/2500, validation error 2.940000 %\n",
      "training @ iter =  90000\n",
      "training @ iter =  90100\n",
      "training @ iter =  90200\n",
      "training @ iter =  90300\n",
      "training @ iter =  90400\n",
      "training @ iter =  90500\n",
      "training @ iter =  90600\n",
      "training @ iter =  90700\n",
      "training @ iter =  90800\n",
      "training @ iter =  90900\n",
      "training @ iter =  91000\n",
      "training @ iter =  91100\n",
      "training @ iter =  91200\n",
      "training @ iter =  91300\n",
      "training @ iter =  91400\n",
      "training @ iter =  91500\n",
      "training @ iter =  91600\n",
      "training @ iter =  91700\n",
      "training @ iter =  91800\n",
      "training @ iter =  91900\n",
      "training @ iter =  92000\n",
      "training @ iter =  92100\n",
      "training @ iter =  92200\n",
      "training @ iter =  92300\n",
      "training @ iter =  92400\n",
      "epoch 37, minibatch 2500/2500, validation error 2.790000 %\n",
      "     epoch 37, minibatch 2500/2500, test error of best model 2.660000 %\n",
      "training @ iter =  92500\n",
      "training @ iter =  92600\n",
      "training @ iter =  92700\n",
      "training @ iter =  92800\n",
      "training @ iter =  92900\n",
      "training @ iter =  93000\n",
      "training @ iter =  93100\n",
      "training @ iter =  93200\n",
      "training @ iter =  93300\n",
      "training @ iter =  93400\n",
      "training @ iter =  93500\n",
      "training @ iter =  93600\n",
      "training @ iter =  93700\n",
      "training @ iter =  93800\n",
      "training @ iter =  93900\n",
      "training @ iter =  94000\n",
      "training @ iter =  94100\n",
      "training @ iter =  94200\n",
      "training @ iter =  94300\n",
      "training @ iter =  94400\n",
      "training @ iter =  94500\n",
      "training @ iter =  94600\n",
      "training @ iter =  94700\n",
      "training @ iter =  94800\n",
      "training @ iter =  94900\n",
      "epoch 38, minibatch 2500/2500, validation error 2.870000 %\n",
      "training @ iter =  95000\n",
      "training @ iter =  95100\n",
      "training @ iter =  95200\n",
      "training @ iter =  95300\n",
      "training @ iter =  95400\n",
      "training @ iter =  95500\n",
      "training @ iter =  95600\n",
      "training @ iter =  95700\n",
      "training @ iter =  95800\n",
      "training @ iter =  95900\n",
      "training @ iter =  96000\n",
      "training @ iter =  96100\n",
      "training @ iter =  96200\n",
      "training @ iter =  96300\n",
      "training @ iter =  96400\n",
      "training @ iter =  96500\n",
      "training @ iter =  96600\n",
      "training @ iter =  96700\n",
      "training @ iter =  96800\n",
      "training @ iter =  96900\n",
      "training @ iter =  97000\n",
      "training @ iter =  97100\n",
      "training @ iter =  97200\n",
      "training @ iter =  97300\n",
      "training @ iter =  97400\n",
      "epoch 39, minibatch 2500/2500, validation error 2.870000 %\n",
      "training @ iter =  97500\n",
      "training @ iter =  97600\n",
      "training @ iter =  97700\n",
      "training @ iter =  97800\n",
      "training @ iter =  97900\n",
      "training @ iter =  98000\n",
      "training @ iter =  98100\n",
      "training @ iter =  98200\n",
      "training @ iter =  98300\n",
      "training @ iter =  98400\n",
      "training @ iter =  98500\n",
      "training @ iter =  98600\n",
      "training @ iter =  98700\n",
      "training @ iter =  98800\n",
      "training @ iter =  98900\n",
      "training @ iter =  99000\n",
      "training @ iter =  99100\n",
      "training @ iter =  99200\n",
      "training @ iter =  99300\n",
      "training @ iter =  99400\n",
      "training @ iter =  99500\n",
      "training @ iter =  99600\n",
      "training @ iter =  99700\n",
      "training @ iter =  99800\n",
      "training @ iter =  99900\n",
      "epoch 40, minibatch 2500/2500, validation error 2.790000 %\n",
      "training @ iter =  100000\n",
      "training @ iter =  100100\n",
      "training @ iter =  100200\n",
      "training @ iter =  100300\n",
      "training @ iter =  100400\n",
      "training @ iter =  100500\n",
      "training @ iter =  100600\n",
      "training @ iter =  100700\n",
      "training @ iter =  100800\n",
      "training @ iter =  100900\n",
      "training @ iter =  101000\n",
      "training @ iter =  101100\n",
      "training @ iter =  101200\n",
      "training @ iter =  101300\n",
      "training @ iter =  101400\n",
      "training @ iter =  101500\n",
      "training @ iter =  101600\n",
      "training @ iter =  101700\n",
      "training @ iter =  101800\n",
      "training @ iter =  101900\n",
      "training @ iter =  102000\n",
      "training @ iter =  102100\n",
      "training @ iter =  102200\n",
      "training @ iter =  102300\n",
      "training @ iter =  102400\n",
      "epoch 41, minibatch 2500/2500, validation error 2.740000 %\n",
      "     epoch 41, minibatch 2500/2500, test error of best model 2.720000 %\n",
      "training @ iter =  102500\n",
      "training @ iter =  102600\n",
      "training @ iter =  102700\n",
      "training @ iter =  102800\n",
      "training @ iter =  102900\n",
      "training @ iter =  103000\n",
      "training @ iter =  103100\n",
      "training @ iter =  103200\n",
      "training @ iter =  103300\n",
      "training @ iter =  103400\n",
      "training @ iter =  103500\n",
      "training @ iter =  103600\n",
      "training @ iter =  103700\n",
      "training @ iter =  103800\n",
      "training @ iter =  103900\n",
      "training @ iter =  104000\n",
      "training @ iter =  104100\n",
      "training @ iter =  104200\n",
      "training @ iter =  104300\n",
      "training @ iter =  104400\n",
      "training @ iter =  104500\n",
      "training @ iter =  104600\n",
      "training @ iter =  104700\n",
      "training @ iter =  104800\n",
      "training @ iter =  104900\n",
      "epoch 42, minibatch 2500/2500, validation error 2.630000 %\n",
      "     epoch 42, minibatch 2500/2500, test error of best model 2.630000 %\n",
      "training @ iter =  105000\n",
      "training @ iter =  105100\n",
      "training @ iter =  105200\n",
      "training @ iter =  105300\n",
      "training @ iter =  105400\n",
      "training @ iter =  105500\n",
      "training @ iter =  105600\n",
      "training @ iter =  105700\n",
      "training @ iter =  105800\n",
      "training @ iter =  105900\n",
      "training @ iter =  106000\n",
      "training @ iter =  106100\n",
      "training @ iter =  106200\n",
      "training @ iter =  106300\n",
      "training @ iter =  106400\n",
      "training @ iter =  106500\n",
      "training @ iter =  106600\n",
      "training @ iter =  106700\n",
      "training @ iter =  106800\n",
      "training @ iter =  106900\n",
      "training @ iter =  107000\n",
      "training @ iter =  107100\n",
      "training @ iter =  107200\n",
      "training @ iter =  107300\n",
      "training @ iter =  107400\n",
      "epoch 43, minibatch 2500/2500, validation error 2.620000 %\n",
      "     epoch 43, minibatch 2500/2500, test error of best model 2.560000 %\n",
      "training @ iter =  107500\n",
      "training @ iter =  107600\n",
      "training @ iter =  107700\n",
      "training @ iter =  107800\n",
      "training @ iter =  107900\n",
      "training @ iter =  108000\n",
      "training @ iter =  108100\n",
      "training @ iter =  108200\n",
      "training @ iter =  108300\n",
      "training @ iter =  108400\n",
      "training @ iter =  108500\n",
      "training @ iter =  108600\n",
      "training @ iter =  108700\n",
      "training @ iter =  108800\n",
      "training @ iter =  108900\n",
      "training @ iter =  109000\n",
      "training @ iter =  109100\n",
      "training @ iter =  109200\n",
      "training @ iter =  109300\n",
      "training @ iter =  109400\n",
      "training @ iter =  109500\n",
      "training @ iter =  109600\n",
      "training @ iter =  109700\n",
      "training @ iter =  109800\n",
      "training @ iter =  109900\n",
      "epoch 44, minibatch 2500/2500, validation error 2.700000 %\n",
      "training @ iter =  110000\n",
      "training @ iter =  110100\n",
      "training @ iter =  110200\n",
      "training @ iter =  110300\n",
      "training @ iter =  110400\n",
      "training @ iter =  110500\n",
      "training @ iter =  110600\n",
      "training @ iter =  110700\n",
      "training @ iter =  110800\n",
      "training @ iter =  110900\n",
      "training @ iter =  111000\n",
      "training @ iter =  111100\n",
      "training @ iter =  111200\n",
      "training @ iter =  111300\n",
      "training @ iter =  111400\n",
      "training @ iter =  111500\n",
      "training @ iter =  111600\n",
      "training @ iter =  111700\n",
      "training @ iter =  111800\n",
      "training @ iter =  111900\n",
      "training @ iter =  112000\n",
      "training @ iter =  112100\n",
      "training @ iter =  112200\n",
      "training @ iter =  112300\n",
      "training @ iter =  112400\n",
      "epoch 45, minibatch 2500/2500, validation error 2.600000 %\n",
      "     epoch 45, minibatch 2500/2500, test error of best model 2.520000 %\n",
      "training @ iter =  112500\n",
      "training @ iter =  112600\n",
      "training @ iter =  112700\n",
      "training @ iter =  112800\n",
      "training @ iter =  112900\n",
      "training @ iter =  113000\n",
      "training @ iter =  113100\n",
      "training @ iter =  113200\n",
      "training @ iter =  113300\n",
      "training @ iter =  113400\n",
      "training @ iter =  113500\n",
      "training @ iter =  113600\n",
      "training @ iter =  113700\n",
      "training @ iter =  113800\n",
      "training @ iter =  113900\n",
      "training @ iter =  114000\n",
      "training @ iter =  114100\n",
      "training @ iter =  114200\n",
      "training @ iter =  114300\n",
      "training @ iter =  114400\n",
      "training @ iter =  114500\n",
      "training @ iter =  114600\n",
      "training @ iter =  114700\n",
      "training @ iter =  114800\n",
      "training @ iter =  114900\n",
      "epoch 46, minibatch 2500/2500, validation error 2.590000 %\n",
      "     epoch 46, minibatch 2500/2500, test error of best model 2.320000 %\n",
      "training @ iter =  115000\n",
      "training @ iter =  115100\n",
      "training @ iter =  115200\n",
      "training @ iter =  115300\n",
      "training @ iter =  115400\n",
      "training @ iter =  115500\n",
      "training @ iter =  115600\n",
      "training @ iter =  115700\n",
      "training @ iter =  115800\n",
      "training @ iter =  115900\n",
      "training @ iter =  116000\n",
      "training @ iter =  116100\n",
      "training @ iter =  116200\n",
      "training @ iter =  116300\n",
      "training @ iter =  116400\n",
      "training @ iter =  116500\n",
      "training @ iter =  116600\n",
      "training @ iter =  116700\n",
      "training @ iter =  116800\n",
      "training @ iter =  116900\n",
      "training @ iter =  117000\n",
      "training @ iter =  117100\n",
      "training @ iter =  117200\n",
      "training @ iter =  117300\n",
      "training @ iter =  117400\n",
      "epoch 47, minibatch 2500/2500, validation error 2.710000 %\n",
      "training @ iter =  117500\n",
      "training @ iter =  117600\n",
      "training @ iter =  117700\n",
      "training @ iter =  117800\n",
      "training @ iter =  117900\n",
      "training @ iter =  118000\n",
      "training @ iter =  118100\n",
      "training @ iter =  118200\n",
      "training @ iter =  118300\n",
      "training @ iter =  118400\n",
      "training @ iter =  118500\n",
      "training @ iter =  118600\n",
      "training @ iter =  118700\n",
      "training @ iter =  118800\n",
      "training @ iter =  118900\n",
      "training @ iter =  119000\n",
      "training @ iter =  119100\n",
      "training @ iter =  119200\n",
      "training @ iter =  119300\n",
      "training @ iter =  119400\n",
      "training @ iter =  119500\n",
      "training @ iter =  119600\n",
      "training @ iter =  119700\n",
      "training @ iter =  119800\n",
      "training @ iter =  119900\n",
      "epoch 48, minibatch 2500/2500, validation error 2.670000 %\n",
      "training @ iter =  120000\n",
      "training @ iter =  120100\n",
      "training @ iter =  120200\n",
      "training @ iter =  120300\n",
      "training @ iter =  120400\n",
      "training @ iter =  120500\n",
      "training @ iter =  120600\n",
      "training @ iter =  120700\n",
      "training @ iter =  120800\n",
      "training @ iter =  120900\n",
      "training @ iter =  121000\n",
      "training @ iter =  121100\n",
      "training @ iter =  121200\n",
      "training @ iter =  121300\n",
      "training @ iter =  121400\n",
      "training @ iter =  121500\n",
      "training @ iter =  121600\n",
      "training @ iter =  121700\n",
      "training @ iter =  121800\n",
      "training @ iter =  121900\n",
      "training @ iter =  122000\n",
      "training @ iter =  122100\n",
      "training @ iter =  122200\n",
      "training @ iter =  122300\n",
      "training @ iter =  122400\n",
      "epoch 49, minibatch 2500/2500, validation error 2.640000 %\n",
      "training @ iter =  122500\n",
      "training @ iter =  122600\n",
      "training @ iter =  122700\n",
      "training @ iter =  122800\n",
      "training @ iter =  122900\n",
      "training @ iter =  123000\n",
      "training @ iter =  123100\n",
      "training @ iter =  123200\n",
      "training @ iter =  123300\n",
      "training @ iter =  123400\n",
      "training @ iter =  123500\n",
      "training @ iter =  123600\n",
      "training @ iter =  123700\n",
      "training @ iter =  123800\n",
      "training @ iter =  123900\n",
      "training @ iter =  124000\n",
      "training @ iter =  124100\n",
      "training @ iter =  124200\n",
      "training @ iter =  124300\n",
      "training @ iter =  124400\n",
      "training @ iter =  124500\n",
      "training @ iter =  124600\n",
      "training @ iter =  124700\n",
      "training @ iter =  124800\n",
      "training @ iter =  124900\n",
      "epoch 50, minibatch 2500/2500, validation error 2.680000 %\n",
      "training @ iter =  125000\n",
      "training @ iter =  125100\n",
      "training @ iter =  125200\n",
      "training @ iter =  125300\n",
      "training @ iter =  125400\n",
      "training @ iter =  125500\n",
      "training @ iter =  125600\n",
      "training @ iter =  125700\n",
      "training @ iter =  125800\n",
      "training @ iter =  125900\n",
      "training @ iter =  126000\n",
      "training @ iter =  126100\n",
      "training @ iter =  126200\n",
      "training @ iter =  126300\n",
      "training @ iter =  126400\n",
      "training @ iter =  126500\n",
      "training @ iter =  126600\n",
      "training @ iter =  126700\n",
      "training @ iter =  126800\n",
      "training @ iter =  126900\n",
      "training @ iter =  127000\n",
      "training @ iter =  127100\n",
      "training @ iter =  127200\n",
      "training @ iter =  127300\n",
      "training @ iter =  127400\n",
      "epoch 51, minibatch 2500/2500, validation error 2.570000 %\n",
      "     epoch 51, minibatch 2500/2500, test error of best model 2.680000 %\n",
      "training @ iter =  127500\n",
      "training @ iter =  127600\n",
      "training @ iter =  127700\n",
      "training @ iter =  127800\n",
      "training @ iter =  127900\n",
      "training @ iter =  128000\n",
      "training @ iter =  128100\n",
      "training @ iter =  128200\n",
      "training @ iter =  128300\n",
      "training @ iter =  128400\n",
      "training @ iter =  128500\n",
      "training @ iter =  128600\n",
      "training @ iter =  128700\n",
      "training @ iter =  128800\n",
      "training @ iter =  128900\n",
      "training @ iter =  129000\n",
      "training @ iter =  129100\n",
      "training @ iter =  129200\n",
      "training @ iter =  129300\n",
      "training @ iter =  129400\n",
      "training @ iter =  129500\n",
      "training @ iter =  129600\n",
      "training @ iter =  129700\n",
      "training @ iter =  129800\n",
      "training @ iter =  129900\n",
      "epoch 52, minibatch 2500/2500, validation error 2.550000 %\n",
      "     epoch 52, minibatch 2500/2500, test error of best model 2.430000 %\n",
      "training @ iter =  130000\n",
      "training @ iter =  130100\n",
      "training @ iter =  130200\n",
      "training @ iter =  130300\n",
      "training @ iter =  130400\n",
      "training @ iter =  130500\n",
      "training @ iter =  130600\n",
      "training @ iter =  130700\n",
      "training @ iter =  130800\n",
      "training @ iter =  130900\n",
      "training @ iter =  131000\n",
      "training @ iter =  131100\n",
      "training @ iter =  131200\n",
      "training @ iter =  131300\n",
      "training @ iter =  131400\n",
      "training @ iter =  131500\n",
      "training @ iter =  131600\n",
      "training @ iter =  131700\n",
      "training @ iter =  131800\n",
      "training @ iter =  131900\n",
      "training @ iter =  132000\n",
      "training @ iter =  132100\n",
      "training @ iter =  132200\n",
      "training @ iter =  132300\n",
      "training @ iter =  132400\n",
      "epoch 53, minibatch 2500/2500, validation error 2.440000 %\n",
      "     epoch 53, minibatch 2500/2500, test error of best model 2.370000 %\n",
      "training @ iter =  132500\n",
      "training @ iter =  132600\n",
      "training @ iter =  132700\n",
      "training @ iter =  132800\n",
      "training @ iter =  132900\n",
      "training @ iter =  133000\n",
      "training @ iter =  133100\n",
      "training @ iter =  133200\n",
      "training @ iter =  133300\n",
      "training @ iter =  133400\n",
      "training @ iter =  133500\n",
      "training @ iter =  133600\n",
      "training @ iter =  133700\n",
      "training @ iter =  133800\n",
      "training @ iter =  133900\n",
      "training @ iter =  134000\n",
      "training @ iter =  134100\n",
      "training @ iter =  134200\n",
      "training @ iter =  134300\n",
      "training @ iter =  134400\n",
      "training @ iter =  134500\n",
      "training @ iter =  134600\n",
      "training @ iter =  134700\n",
      "training @ iter =  134800\n",
      "training @ iter =  134900\n",
      "epoch 54, minibatch 2500/2500, validation error 2.400000 %\n",
      "     epoch 54, minibatch 2500/2500, test error of best model 2.500000 %\n",
      "training @ iter =  135000\n",
      "training @ iter =  135100\n",
      "training @ iter =  135200\n",
      "training @ iter =  135300\n",
      "training @ iter =  135400\n",
      "training @ iter =  135500\n",
      "training @ iter =  135600\n",
      "training @ iter =  135700\n",
      "training @ iter =  135800\n",
      "training @ iter =  135900\n",
      "training @ iter =  136000\n",
      "training @ iter =  136100\n",
      "training @ iter =  136200\n",
      "training @ iter =  136300\n",
      "training @ iter =  136400\n",
      "training @ iter =  136500\n",
      "training @ iter =  136600\n",
      "training @ iter =  136700\n",
      "training @ iter =  136800\n",
      "training @ iter =  136900\n",
      "training @ iter =  137000\n",
      "training @ iter =  137100\n",
      "training @ iter =  137200\n",
      "training @ iter =  137300\n",
      "training @ iter =  137400\n",
      "epoch 55, minibatch 2500/2500, validation error 2.600000 %\n",
      "Validation error not improved for 10 epochs, changing the learning rate to 0.00125\n",
      "training @ iter =  137500\n",
      "training @ iter =  137600\n",
      "training @ iter =  137700\n",
      "training @ iter =  137800\n",
      "training @ iter =  137900\n",
      "training @ iter =  138000\n",
      "training @ iter =  138100\n",
      "training @ iter =  138200\n",
      "training @ iter =  138300\n",
      "training @ iter =  138400\n",
      "training @ iter =  138500\n",
      "training @ iter =  138600\n",
      "training @ iter =  138700\n",
      "training @ iter =  138800\n",
      "training @ iter =  138900\n",
      "training @ iter =  139000\n",
      "training @ iter =  139100\n",
      "training @ iter =  139200\n",
      "training @ iter =  139300\n",
      "training @ iter =  139400\n",
      "training @ iter =  139500\n",
      "training @ iter =  139600\n",
      "training @ iter =  139700\n",
      "training @ iter =  139800\n",
      "training @ iter =  139900\n",
      "epoch 56, minibatch 2500/2500, validation error 2.650000 %\n",
      "training @ iter =  140000\n",
      "training @ iter =  140100\n",
      "training @ iter =  140200\n",
      "training @ iter =  140300\n",
      "training @ iter =  140400\n",
      "training @ iter =  140500\n",
      "training @ iter =  140600\n",
      "training @ iter =  140700\n",
      "training @ iter =  140800\n",
      "training @ iter =  140900\n",
      "training @ iter =  141000\n",
      "training @ iter =  141100\n",
      "training @ iter =  141200\n",
      "training @ iter =  141300\n",
      "training @ iter =  141400\n",
      "training @ iter =  141500\n",
      "training @ iter =  141600\n",
      "training @ iter =  141700\n",
      "training @ iter =  141800\n",
      "training @ iter =  141900\n",
      "training @ iter =  142000\n",
      "training @ iter =  142100\n",
      "training @ iter =  142200\n",
      "training @ iter =  142300\n",
      "training @ iter =  142400\n",
      "epoch 57, minibatch 2500/2500, validation error 2.290000 %\n",
      "     epoch 57, minibatch 2500/2500, test error of best model 2.600000 %\n",
      "training @ iter =  142500\n",
      "training @ iter =  142600\n",
      "training @ iter =  142700\n",
      "training @ iter =  142800\n",
      "training @ iter =  142900\n",
      "training @ iter =  143000\n",
      "training @ iter =  143100\n",
      "training @ iter =  143200\n",
      "training @ iter =  143300\n",
      "training @ iter =  143400\n",
      "training @ iter =  143500\n",
      "training @ iter =  143600\n",
      "training @ iter =  143700\n",
      "training @ iter =  143800\n",
      "training @ iter =  143900\n",
      "training @ iter =  144000\n",
      "training @ iter =  144100\n",
      "training @ iter =  144200\n",
      "training @ iter =  144300\n",
      "training @ iter =  144400\n",
      "training @ iter =  144500\n",
      "training @ iter =  144600\n",
      "training @ iter =  144700\n",
      "training @ iter =  144800\n",
      "training @ iter =  144900\n",
      "epoch 58, minibatch 2500/2500, validation error 2.710000 %\n",
      "training @ iter =  145000\n",
      "training @ iter =  145100\n",
      "training @ iter =  145200\n",
      "training @ iter =  145300\n",
      "training @ iter =  145400\n",
      "training @ iter =  145500\n",
      "training @ iter =  145600\n",
      "training @ iter =  145700\n",
      "training @ iter =  145800\n",
      "training @ iter =  145900\n",
      "training @ iter =  146000\n",
      "training @ iter =  146100\n",
      "training @ iter =  146200\n",
      "training @ iter =  146300\n",
      "training @ iter =  146400\n",
      "training @ iter =  146500\n",
      "training @ iter =  146600\n",
      "training @ iter =  146700\n",
      "training @ iter =  146800\n",
      "training @ iter =  146900\n",
      "training @ iter =  147000\n",
      "training @ iter =  147100\n",
      "training @ iter =  147200\n",
      "training @ iter =  147300\n",
      "training @ iter =  147400\n",
      "epoch 59, minibatch 2500/2500, validation error 2.430000 %\n",
      "training @ iter =  147500\n",
      "training @ iter =  147600\n",
      "training @ iter =  147700\n",
      "training @ iter =  147800\n",
      "training @ iter =  147900\n",
      "training @ iter =  148000\n",
      "training @ iter =  148100\n",
      "training @ iter =  148200\n",
      "training @ iter =  148300\n",
      "training @ iter =  148400\n",
      "training @ iter =  148500\n",
      "training @ iter =  148600\n",
      "training @ iter =  148700\n",
      "training @ iter =  148800\n",
      "training @ iter =  148900\n",
      "training @ iter =  149000\n",
      "training @ iter =  149100\n",
      "training @ iter =  149200\n",
      "training @ iter =  149300\n",
      "training @ iter =  149400\n",
      "training @ iter =  149500\n",
      "training @ iter =  149600\n",
      "training @ iter =  149700\n",
      "training @ iter =  149800\n",
      "training @ iter =  149900\n",
      "epoch 60, minibatch 2500/2500, validation error 2.380000 %\n",
      "training @ iter =  150000\n",
      "training @ iter =  150100\n",
      "training @ iter =  150200\n",
      "training @ iter =  150300\n",
      "training @ iter =  150400\n",
      "training @ iter =  150500\n",
      "training @ iter =  150600\n",
      "training @ iter =  150700\n",
      "training @ iter =  150800\n",
      "training @ iter =  150900\n",
      "training @ iter =  151000\n",
      "training @ iter =  151100\n",
      "training @ iter =  151200\n",
      "training @ iter =  151300\n",
      "training @ iter =  151400\n",
      "training @ iter =  151500\n",
      "training @ iter =  151600\n",
      "training @ iter =  151700\n",
      "training @ iter =  151800\n",
      "training @ iter =  151900\n",
      "training @ iter =  152000\n",
      "training @ iter =  152100\n",
      "training @ iter =  152200\n",
      "training @ iter =  152300\n",
      "training @ iter =  152400\n",
      "epoch 61, minibatch 2500/2500, validation error 2.160000 %\n",
      "     epoch 61, minibatch 2500/2500, test error of best model 2.310000 %\n",
      "training @ iter =  152500\n",
      "training @ iter =  152600\n",
      "training @ iter =  152700\n",
      "training @ iter =  152800\n",
      "training @ iter =  152900\n",
      "training @ iter =  153000\n",
      "training @ iter =  153100\n",
      "training @ iter =  153200\n",
      "training @ iter =  153300\n",
      "training @ iter =  153400\n",
      "training @ iter =  153500\n",
      "training @ iter =  153600\n",
      "training @ iter =  153700\n",
      "training @ iter =  153800\n",
      "training @ iter =  153900\n",
      "training @ iter =  154000\n",
      "training @ iter =  154100\n",
      "training @ iter =  154200\n",
      "training @ iter =  154300\n",
      "training @ iter =  154400\n",
      "training @ iter =  154500\n",
      "training @ iter =  154600\n",
      "training @ iter =  154700\n",
      "training @ iter =  154800\n",
      "training @ iter =  154900\n",
      "epoch 62, minibatch 2500/2500, validation error 2.280000 %\n",
      "training @ iter =  155000\n",
      "training @ iter =  155100\n",
      "training @ iter =  155200\n",
      "training @ iter =  155300\n",
      "training @ iter =  155400\n",
      "training @ iter =  155500\n",
      "training @ iter =  155600\n",
      "training @ iter =  155700\n",
      "training @ iter =  155800\n",
      "training @ iter =  155900\n",
      "training @ iter =  156000\n",
      "training @ iter =  156100\n",
      "training @ iter =  156200\n",
      "training @ iter =  156300\n",
      "training @ iter =  156400\n",
      "training @ iter =  156500\n",
      "training @ iter =  156600\n",
      "training @ iter =  156700\n",
      "training @ iter =  156800\n",
      "training @ iter =  156900\n",
      "training @ iter =  157000\n",
      "training @ iter =  157100\n",
      "training @ iter =  157200\n",
      "training @ iter =  157300\n",
      "training @ iter =  157400\n",
      "epoch 63, minibatch 2500/2500, validation error 2.450000 %\n",
      "training @ iter =  157500\n",
      "training @ iter =  157600\n",
      "training @ iter =  157700\n",
      "training @ iter =  157800\n",
      "training @ iter =  157900\n",
      "training @ iter =  158000\n",
      "training @ iter =  158100\n",
      "training @ iter =  158200\n",
      "training @ iter =  158300\n",
      "training @ iter =  158400\n",
      "training @ iter =  158500\n",
      "training @ iter =  158600\n",
      "training @ iter =  158700\n",
      "training @ iter =  158800\n",
      "training @ iter =  158900\n",
      "training @ iter =  159000\n",
      "training @ iter =  159100\n",
      "training @ iter =  159200\n",
      "training @ iter =  159300\n",
      "training @ iter =  159400\n",
      "training @ iter =  159500\n",
      "training @ iter =  159600\n",
      "training @ iter =  159700\n",
      "training @ iter =  159800\n",
      "training @ iter =  159900\n",
      "epoch 64, minibatch 2500/2500, validation error 2.630000 %\n",
      "training @ iter =  160000\n",
      "training @ iter =  160100\n",
      "training @ iter =  160200\n",
      "training @ iter =  160300\n",
      "training @ iter =  160400\n",
      "training @ iter =  160500\n",
      "training @ iter =  160600\n",
      "training @ iter =  160700\n",
      "training @ iter =  160800\n",
      "training @ iter =  160900\n",
      "training @ iter =  161000\n",
      "training @ iter =  161100\n",
      "training @ iter =  161200\n",
      "training @ iter =  161300\n",
      "training @ iter =  161400\n",
      "training @ iter =  161500\n",
      "training @ iter =  161600\n",
      "training @ iter =  161700\n",
      "training @ iter =  161800\n",
      "training @ iter =  161900\n",
      "training @ iter =  162000\n",
      "training @ iter =  162100\n",
      "training @ iter =  162200\n",
      "training @ iter =  162300\n",
      "training @ iter =  162400\n",
      "epoch 65, minibatch 2500/2500, validation error 2.460000 %\n",
      "training @ iter =  162500\n",
      "training @ iter =  162600\n",
      "training @ iter =  162700\n",
      "training @ iter =  162800\n",
      "training @ iter =  162900\n",
      "training @ iter =  163000\n",
      "training @ iter =  163100\n",
      "training @ iter =  163200\n",
      "training @ iter =  163300\n",
      "training @ iter =  163400\n",
      "training @ iter =  163500\n",
      "training @ iter =  163600\n",
      "training @ iter =  163700\n",
      "training @ iter =  163800\n",
      "training @ iter =  163900\n",
      "training @ iter =  164000\n",
      "training @ iter =  164100\n",
      "training @ iter =  164200\n",
      "training @ iter =  164300\n",
      "training @ iter =  164400\n",
      "training @ iter =  164500\n",
      "training @ iter =  164600\n",
      "training @ iter =  164700\n",
      "training @ iter =  164800\n",
      "training @ iter =  164900\n",
      "epoch 66, minibatch 2500/2500, validation error 2.550000 %\n",
      "training @ iter =  165000\n",
      "training @ iter =  165100\n",
      "training @ iter =  165200\n",
      "training @ iter =  165300\n",
      "training @ iter =  165400\n",
      "training @ iter =  165500\n",
      "training @ iter =  165600\n",
      "training @ iter =  165700\n",
      "training @ iter =  165800\n",
      "training @ iter =  165900\n",
      "training @ iter =  166000\n",
      "training @ iter =  166100\n",
      "training @ iter =  166200\n",
      "training @ iter =  166300\n",
      "training @ iter =  166400\n",
      "training @ iter =  166500\n",
      "training @ iter =  166600\n",
      "training @ iter =  166700\n",
      "training @ iter =  166800\n",
      "training @ iter =  166900\n",
      "training @ iter =  167000\n",
      "training @ iter =  167100\n",
      "training @ iter =  167200\n",
      "training @ iter =  167300\n",
      "training @ iter =  167400\n",
      "epoch 67, minibatch 2500/2500, validation error 2.270000 %\n",
      "Validation error not improved for 10 epochs, changing the learning rate to 0.000625\n",
      "training @ iter =  167500\n",
      "training @ iter =  167600\n",
      "training @ iter =  167700\n",
      "training @ iter =  167800\n",
      "training @ iter =  167900\n",
      "training @ iter =  168000\n",
      "training @ iter =  168100\n",
      "training @ iter =  168200\n",
      "training @ iter =  168300\n",
      "training @ iter =  168400\n",
      "training @ iter =  168500\n",
      "training @ iter =  168600\n",
      "training @ iter =  168700\n",
      "training @ iter =  168800\n",
      "training @ iter =  168900\n",
      "training @ iter =  169000\n",
      "training @ iter =  169100\n",
      "training @ iter =  169200\n",
      "training @ iter =  169300\n",
      "training @ iter =  169400\n",
      "training @ iter =  169500\n",
      "training @ iter =  169600\n",
      "training @ iter =  169700\n",
      "training @ iter =  169800\n",
      "training @ iter =  169900\n",
      "epoch 68, minibatch 2500/2500, validation error 2.290000 %\n",
      "training @ iter =  170000\n",
      "training @ iter =  170100\n",
      "training @ iter =  170200\n",
      "training @ iter =  170300\n",
      "training @ iter =  170400\n",
      "training @ iter =  170500\n",
      "training @ iter =  170600\n",
      "training @ iter =  170700\n",
      "training @ iter =  170800\n",
      "training @ iter =  170900\n",
      "training @ iter =  171000\n",
      "training @ iter =  171100\n",
      "training @ iter =  171200\n",
      "training @ iter =  171300\n",
      "training @ iter =  171400\n",
      "training @ iter =  171500\n",
      "training @ iter =  171600\n",
      "training @ iter =  171700\n",
      "training @ iter =  171800\n",
      "training @ iter =  171900\n",
      "training @ iter =  172000\n",
      "training @ iter =  172100\n",
      "training @ iter =  172200\n",
      "training @ iter =  172300\n",
      "training @ iter =  172400\n",
      "epoch 69, minibatch 2500/2500, validation error 2.280000 %\n",
      "training @ iter =  172500\n",
      "training @ iter =  172600\n",
      "training @ iter =  172700\n",
      "training @ iter =  172800\n",
      "training @ iter =  172900\n",
      "training @ iter =  173000\n",
      "training @ iter =  173100\n",
      "training @ iter =  173200\n",
      "training @ iter =  173300\n",
      "training @ iter =  173400\n",
      "training @ iter =  173500\n",
      "training @ iter =  173600\n",
      "training @ iter =  173700\n",
      "training @ iter =  173800\n",
      "training @ iter =  173900\n",
      "training @ iter =  174000\n",
      "training @ iter =  174100\n",
      "training @ iter =  174200\n",
      "training @ iter =  174300\n",
      "training @ iter =  174400\n",
      "training @ iter =  174500\n",
      "training @ iter =  174600\n",
      "training @ iter =  174700\n",
      "training @ iter =  174800\n",
      "training @ iter =  174900\n",
      "epoch 70, minibatch 2500/2500, validation error 2.510000 %\n",
      "training @ iter =  175000\n",
      "training @ iter =  175100\n",
      "training @ iter =  175200\n",
      "training @ iter =  175300\n",
      "training @ iter =  175400\n",
      "training @ iter =  175500\n",
      "training @ iter =  175600\n",
      "training @ iter =  175700\n",
      "training @ iter =  175800\n",
      "training @ iter =  175900\n",
      "training @ iter =  176000\n",
      "training @ iter =  176100\n",
      "training @ iter =  176200\n",
      "training @ iter =  176300\n",
      "training @ iter =  176400\n",
      "training @ iter =  176500\n",
      "training @ iter =  176600\n",
      "training @ iter =  176700\n",
      "training @ iter =  176800\n",
      "training @ iter =  176900\n",
      "training @ iter =  177000\n",
      "training @ iter =  177100\n",
      "training @ iter =  177200\n",
      "training @ iter =  177300\n",
      "training @ iter =  177400\n",
      "epoch 71, minibatch 2500/2500, validation error 2.440000 %\n",
      "training @ iter =  177500\n",
      "training @ iter =  177600\n",
      "training @ iter =  177700\n",
      "training @ iter =  177800\n",
      "training @ iter =  177900\n",
      "training @ iter =  178000\n",
      "training @ iter =  178100\n",
      "training @ iter =  178200\n",
      "training @ iter =  178300\n",
      "training @ iter =  178400\n",
      "training @ iter =  178500\n",
      "training @ iter =  178600\n",
      "training @ iter =  178700\n",
      "training @ iter =  178800\n",
      "training @ iter =  178900\n",
      "training @ iter =  179000\n",
      "training @ iter =  179100\n",
      "training @ iter =  179200\n",
      "training @ iter =  179300\n",
      "training @ iter =  179400\n",
      "training @ iter =  179500\n",
      "training @ iter =  179600\n",
      "training @ iter =  179700\n",
      "training @ iter =  179800\n",
      "training @ iter =  179900\n",
      "epoch 72, minibatch 2500/2500, validation error 2.370000 %\n",
      "training @ iter =  180000\n",
      "training @ iter =  180100\n",
      "training @ iter =  180200\n",
      "training @ iter =  180300\n",
      "training @ iter =  180400\n",
      "training @ iter =  180500\n",
      "training @ iter =  180600\n",
      "training @ iter =  180700\n",
      "training @ iter =  180800\n",
      "training @ iter =  180900\n",
      "training @ iter =  181000\n",
      "training @ iter =  181100\n",
      "training @ iter =  181200\n",
      "training @ iter =  181300\n",
      "training @ iter =  181400\n",
      "training @ iter =  181500\n",
      "training @ iter =  181600\n",
      "training @ iter =  181700\n",
      "training @ iter =  181800\n",
      "training @ iter =  181900\n",
      "training @ iter =  182000\n",
      "training @ iter =  182100\n",
      "training @ iter =  182200\n",
      "training @ iter =  182300\n",
      "training @ iter =  182400\n",
      "epoch 73, minibatch 2500/2500, validation error 2.450000 %\n",
      "training @ iter =  182500\n",
      "training @ iter =  182600\n",
      "training @ iter =  182700\n",
      "training @ iter =  182800\n",
      "training @ iter =  182900\n",
      "training @ iter =  183000\n",
      "training @ iter =  183100\n",
      "training @ iter =  183200\n",
      "training @ iter =  183300\n",
      "training @ iter =  183400\n",
      "training @ iter =  183500\n",
      "training @ iter =  183600\n",
      "training @ iter =  183700\n",
      "training @ iter =  183800\n",
      "training @ iter =  183900\n",
      "training @ iter =  184000\n",
      "training @ iter =  184100\n",
      "training @ iter =  184200\n",
      "training @ iter =  184300\n",
      "training @ iter =  184400\n",
      "training @ iter =  184500\n",
      "training @ iter =  184600\n",
      "training @ iter =  184700\n",
      "training @ iter =  184800\n",
      "training @ iter =  184900\n",
      "epoch 74, minibatch 2500/2500, validation error 2.350000 %\n",
      "training @ iter =  185000\n",
      "training @ iter =  185100\n",
      "training @ iter =  185200\n",
      "training @ iter =  185300\n",
      "training @ iter =  185400\n",
      "training @ iter =  185500\n",
      "training @ iter =  185600\n",
      "training @ iter =  185700\n",
      "training @ iter =  185800\n",
      "training @ iter =  185900\n",
      "training @ iter =  186000\n",
      "training @ iter =  186100\n",
      "training @ iter =  186200\n",
      "training @ iter =  186300\n",
      "training @ iter =  186400\n",
      "training @ iter =  186500\n",
      "training @ iter =  186600\n",
      "training @ iter =  186700\n",
      "training @ iter =  186800\n",
      "training @ iter =  186900\n",
      "training @ iter =  187000\n",
      "training @ iter =  187100\n",
      "training @ iter =  187200\n",
      "training @ iter =  187300\n",
      "training @ iter =  187400\n",
      "epoch 75, minibatch 2500/2500, validation error 2.370000 %\n",
      "training @ iter =  187500\n",
      "training @ iter =  187600\n",
      "training @ iter =  187700\n",
      "training @ iter =  187800\n",
      "training @ iter =  187900\n",
      "training @ iter =  188000\n",
      "training @ iter =  188100\n",
      "training @ iter =  188200\n",
      "training @ iter =  188300\n",
      "training @ iter =  188400\n",
      "training @ iter =  188500\n",
      "training @ iter =  188600\n",
      "training @ iter =  188700\n",
      "training @ iter =  188800\n",
      "training @ iter =  188900\n",
      "training @ iter =  189000\n",
      "training @ iter =  189100\n",
      "training @ iter =  189200\n",
      "training @ iter =  189300\n",
      "training @ iter =  189400\n",
      "training @ iter =  189500\n",
      "training @ iter =  189600\n",
      "training @ iter =  189700\n",
      "training @ iter =  189800\n",
      "training @ iter =  189900\n",
      "epoch 76, minibatch 2500/2500, validation error 2.390000 %\n",
      "training @ iter =  190000\n",
      "training @ iter =  190100\n",
      "training @ iter =  190200\n",
      "training @ iter =  190300\n",
      "training @ iter =  190400\n",
      "training @ iter =  190500\n",
      "training @ iter =  190600\n",
      "training @ iter =  190700\n",
      "training @ iter =  190800\n",
      "training @ iter =  190900\n",
      "training @ iter =  191000\n",
      "training @ iter =  191100\n",
      "training @ iter =  191200\n",
      "training @ iter =  191300\n",
      "training @ iter =  191400\n",
      "training @ iter =  191500\n",
      "training @ iter =  191600\n",
      "training @ iter =  191700\n",
      "training @ iter =  191800\n",
      "training @ iter =  191900\n",
      "training @ iter =  192000\n",
      "training @ iter =  192100\n",
      "training @ iter =  192200\n",
      "training @ iter =  192300\n",
      "training @ iter =  192400\n",
      "epoch 77, minibatch 2500/2500, validation error 2.420000 %\n",
      "Validation error not improved for 10 epochs, changing the learning rate to 0.0003125\n",
      "training @ iter =  192500\n",
      "training @ iter =  192600\n",
      "training @ iter =  192700\n",
      "training @ iter =  192800\n",
      "training @ iter =  192900\n",
      "training @ iter =  193000\n",
      "training @ iter =  193100\n",
      "training @ iter =  193200\n",
      "training @ iter =  193300\n",
      "training @ iter =  193400\n",
      "training @ iter =  193500\n",
      "training @ iter =  193600\n",
      "training @ iter =  193700\n",
      "training @ iter =  193800\n",
      "training @ iter =  193900\n",
      "training @ iter =  194000\n",
      "training @ iter =  194100\n",
      "training @ iter =  194200\n",
      "training @ iter =  194300\n",
      "training @ iter =  194400\n",
      "training @ iter =  194500\n",
      "training @ iter =  194600\n",
      "training @ iter =  194700\n",
      "training @ iter =  194800\n",
      "training @ iter =  194900\n",
      "epoch 78, minibatch 2500/2500, validation error 2.370000 %\n",
      "training @ iter =  195000\n",
      "training @ iter =  195100\n",
      "training @ iter =  195200\n",
      "training @ iter =  195300\n",
      "training @ iter =  195400\n",
      "training @ iter =  195500\n",
      "training @ iter =  195600\n",
      "training @ iter =  195700\n",
      "training @ iter =  195800\n",
      "training @ iter =  195900\n",
      "training @ iter =  196000\n",
      "training @ iter =  196100\n",
      "training @ iter =  196200\n",
      "training @ iter =  196300\n",
      "training @ iter =  196400\n",
      "training @ iter =  196500\n",
      "training @ iter =  196600\n",
      "training @ iter =  196700\n",
      "training @ iter =  196800\n",
      "training @ iter =  196900\n",
      "training @ iter =  197000\n",
      "training @ iter =  197100\n",
      "training @ iter =  197200\n",
      "training @ iter =  197300\n",
      "training @ iter =  197400\n",
      "epoch 79, minibatch 2500/2500, validation error 2.530000 %\n",
      "training @ iter =  197500\n",
      "training @ iter =  197600\n",
      "training @ iter =  197700\n",
      "training @ iter =  197800\n",
      "training @ iter =  197900\n",
      "training @ iter =  198000\n",
      "training @ iter =  198100\n",
      "training @ iter =  198200\n",
      "training @ iter =  198300\n",
      "training @ iter =  198400\n",
      "training @ iter =  198500\n",
      "training @ iter =  198600\n",
      "training @ iter =  198700\n",
      "training @ iter =  198800\n",
      "training @ iter =  198900\n",
      "training @ iter =  199000\n",
      "training @ iter =  199100\n",
      "training @ iter =  199200\n",
      "training @ iter =  199300\n",
      "training @ iter =  199400\n",
      "training @ iter =  199500\n",
      "training @ iter =  199600\n",
      "training @ iter =  199700\n",
      "training @ iter =  199800\n",
      "training @ iter =  199900\n",
      "epoch 80, minibatch 2500/2500, validation error 2.240000 %\n",
      "training @ iter =  200000\n",
      "training @ iter =  200100\n",
      "training @ iter =  200200\n",
      "training @ iter =  200300\n",
      "training @ iter =  200400\n",
      "training @ iter =  200500\n",
      "training @ iter =  200600\n",
      "training @ iter =  200700\n",
      "training @ iter =  200800\n",
      "training @ iter =  200900\n",
      "training @ iter =  201000\n",
      "training @ iter =  201100\n",
      "training @ iter =  201200\n",
      "training @ iter =  201300\n",
      "training @ iter =  201400\n",
      "training @ iter =  201500\n",
      "training @ iter =  201600\n",
      "training @ iter =  201700\n",
      "training @ iter =  201800\n",
      "training @ iter =  201900\n",
      "training @ iter =  202000\n",
      "training @ iter =  202100\n",
      "training @ iter =  202200\n",
      "training @ iter =  202300\n",
      "training @ iter =  202400\n",
      "epoch 81, minibatch 2500/2500, validation error 2.490000 %\n",
      "training @ iter =  202500\n",
      "training @ iter =  202600\n",
      "training @ iter =  202700\n",
      "training @ iter =  202800\n",
      "training @ iter =  202900\n",
      "training @ iter =  203000\n",
      "training @ iter =  203100\n",
      "training @ iter =  203200\n",
      "training @ iter =  203300\n",
      "training @ iter =  203400\n",
      "training @ iter =  203500\n",
      "training @ iter =  203600\n",
      "training @ iter =  203700\n",
      "training @ iter =  203800\n",
      "training @ iter =  203900\n",
      "training @ iter =  204000\n",
      "training @ iter =  204100\n",
      "training @ iter =  204200\n",
      "training @ iter =  204300\n",
      "training @ iter =  204400\n",
      "training @ iter =  204500\n",
      "training @ iter =  204600\n",
      "training @ iter =  204700\n",
      "training @ iter =  204800\n",
      "training @ iter =  204900\n",
      "epoch 82, minibatch 2500/2500, validation error 2.420000 %\n",
      "training @ iter =  205000\n",
      "training @ iter =  205100\n",
      "training @ iter =  205200\n",
      "training @ iter =  205300\n",
      "training @ iter =  205400\n",
      "training @ iter =  205500\n",
      "training @ iter =  205600\n",
      "training @ iter =  205700\n",
      "training @ iter =  205800\n",
      "training @ iter =  205900\n",
      "training @ iter =  206000\n",
      "training @ iter =  206100\n",
      "training @ iter =  206200\n",
      "training @ iter =  206300\n",
      "training @ iter =  206400\n",
      "training @ iter =  206500\n",
      "training @ iter =  206600\n",
      "training @ iter =  206700\n",
      "training @ iter =  206800\n",
      "training @ iter =  206900\n",
      "training @ iter =  207000\n",
      "training @ iter =  207100\n",
      "training @ iter =  207200\n",
      "training @ iter =  207300\n",
      "training @ iter =  207400\n",
      "epoch 83, minibatch 2500/2500, validation error 2.340000 %\n",
      "training @ iter =  207500\n",
      "training @ iter =  207600\n",
      "training @ iter =  207700\n",
      "training @ iter =  207800\n",
      "training @ iter =  207900\n",
      "training @ iter =  208000\n",
      "training @ iter =  208100\n",
      "training @ iter =  208200\n",
      "training @ iter =  208300\n",
      "training @ iter =  208400\n",
      "training @ iter =  208500\n",
      "training @ iter =  208600\n",
      "training @ iter =  208700\n",
      "training @ iter =  208800\n",
      "training @ iter =  208900\n",
      "training @ iter =  209000\n",
      "training @ iter =  209100\n",
      "training @ iter =  209200\n",
      "training @ iter =  209300\n",
      "training @ iter =  209400\n",
      "training @ iter =  209500\n",
      "training @ iter =  209600\n",
      "training @ iter =  209700\n",
      "training @ iter =  209800\n",
      "training @ iter =  209900\n",
      "epoch 84, minibatch 2500/2500, validation error 2.450000 %\n",
      "training @ iter =  210000\n",
      "training @ iter =  210100\n",
      "training @ iter =  210200\n",
      "training @ iter =  210300\n",
      "training @ iter =  210400\n",
      "training @ iter =  210500\n",
      "training @ iter =  210600\n",
      "training @ iter =  210700\n",
      "training @ iter =  210800\n",
      "training @ iter =  210900\n",
      "training @ iter =  211000\n",
      "training @ iter =  211100\n",
      "training @ iter =  211200\n",
      "training @ iter =  211300\n",
      "training @ iter =  211400\n",
      "training @ iter =  211500\n",
      "training @ iter =  211600\n",
      "training @ iter =  211700\n",
      "training @ iter =  211800\n",
      "training @ iter =  211900\n",
      "training @ iter =  212000\n",
      "training @ iter =  212100\n",
      "training @ iter =  212200\n",
      "training @ iter =  212300\n",
      "training @ iter =  212400\n",
      "epoch 85, minibatch 2500/2500, validation error 2.390000 %\n",
      "training @ iter =  212500\n",
      "training @ iter =  212600\n",
      "training @ iter =  212700\n",
      "training @ iter =  212800\n",
      "training @ iter =  212900\n",
      "training @ iter =  213000\n",
      "training @ iter =  213100\n",
      "training @ iter =  213200\n",
      "training @ iter =  213300\n",
      "training @ iter =  213400\n",
      "training @ iter =  213500\n",
      "training @ iter =  213600\n",
      "training @ iter =  213700\n",
      "training @ iter =  213800\n",
      "training @ iter =  213900\n",
      "training @ iter =  214000\n",
      "training @ iter =  214100\n",
      "training @ iter =  214200\n",
      "training @ iter =  214300\n",
      "training @ iter =  214400\n",
      "training @ iter =  214500\n",
      "training @ iter =  214600\n",
      "training @ iter =  214700\n",
      "training @ iter =  214800\n",
      "training @ iter =  214900\n",
      "epoch 86, minibatch 2500/2500, validation error 2.280000 %\n",
      "training @ iter =  215000\n",
      "training @ iter =  215100\n",
      "training @ iter =  215200\n",
      "training @ iter =  215300\n",
      "training @ iter =  215400\n",
      "training @ iter =  215500\n",
      "training @ iter =  215600\n",
      "training @ iter =  215700\n",
      "training @ iter =  215800\n",
      "training @ iter =  215900\n",
      "training @ iter =  216000\n",
      "training @ iter =  216100\n",
      "training @ iter =  216200\n",
      "training @ iter =  216300\n",
      "training @ iter =  216400\n",
      "training @ iter =  216500\n",
      "training @ iter =  216600\n",
      "training @ iter =  216700\n",
      "training @ iter =  216800\n",
      "training @ iter =  216900\n",
      "training @ iter =  217000\n",
      "training @ iter =  217100\n",
      "training @ iter =  217200\n",
      "training @ iter =  217300\n",
      "training @ iter =  217400\n",
      "epoch 87, minibatch 2500/2500, validation error 2.460000 %\n",
      "Validation error not improved for 10 epochs, changing the learning rate to 0.00015625\n",
      "training @ iter =  217500\n",
      "training @ iter =  217600\n",
      "training @ iter =  217700\n",
      "training @ iter =  217800\n",
      "training @ iter =  217900\n",
      "training @ iter =  218000\n",
      "training @ iter =  218100\n",
      "training @ iter =  218200\n",
      "training @ iter =  218300\n",
      "training @ iter =  218400\n",
      "training @ iter =  218500\n",
      "training @ iter =  218600\n",
      "training @ iter =  218700\n",
      "training @ iter =  218800\n",
      "training @ iter =  218900\n",
      "training @ iter =  219000\n",
      "training @ iter =  219100\n",
      "training @ iter =  219200\n",
      "training @ iter =  219300\n",
      "training @ iter =  219400\n",
      "training @ iter =  219500\n",
      "training @ iter =  219600\n",
      "training @ iter =  219700\n",
      "training @ iter =  219800\n",
      "training @ iter =  219900\n",
      "epoch 88, minibatch 2500/2500, validation error 2.520000 %\n",
      "training @ iter =  220000\n",
      "training @ iter =  220100\n",
      "training @ iter =  220200\n",
      "training @ iter =  220300\n",
      "training @ iter =  220400\n",
      "training @ iter =  220500\n",
      "training @ iter =  220600\n",
      "training @ iter =  220700\n",
      "training @ iter =  220800\n",
      "training @ iter =  220900\n",
      "training @ iter =  221000\n",
      "training @ iter =  221100\n",
      "training @ iter =  221200\n",
      "training @ iter =  221300\n",
      "training @ iter =  221400\n",
      "training @ iter =  221500\n",
      "training @ iter =  221600\n",
      "training @ iter =  221700\n",
      "training @ iter =  221800\n",
      "training @ iter =  221900\n",
      "training @ iter =  222000\n",
      "training @ iter =  222100\n",
      "training @ iter =  222200\n",
      "training @ iter =  222300\n",
      "training @ iter =  222400\n",
      "epoch 89, minibatch 2500/2500, validation error 2.350000 %\n",
      "training @ iter =  222500\n",
      "training @ iter =  222600\n",
      "training @ iter =  222700\n",
      "training @ iter =  222800\n",
      "training @ iter =  222900\n",
      "training @ iter =  223000\n",
      "training @ iter =  223100\n",
      "training @ iter =  223200\n",
      "training @ iter =  223300\n",
      "training @ iter =  223400\n",
      "training @ iter =  223500\n",
      "training @ iter =  223600\n",
      "training @ iter =  223700\n",
      "training @ iter =  223800\n",
      "training @ iter =  223900\n",
      "training @ iter =  224000\n",
      "training @ iter =  224100\n",
      "training @ iter =  224200\n",
      "training @ iter =  224300\n",
      "training @ iter =  224400\n",
      "training @ iter =  224500\n",
      "training @ iter =  224600\n",
      "training @ iter =  224700\n",
      "training @ iter =  224800\n",
      "training @ iter =  224900\n",
      "epoch 90, minibatch 2500/2500, validation error 2.450000 %\n",
      "training @ iter =  225000\n",
      "training @ iter =  225100\n",
      "training @ iter =  225200\n",
      "training @ iter =  225300\n",
      "training @ iter =  225400\n",
      "training @ iter =  225500\n",
      "training @ iter =  225600\n",
      "training @ iter =  225700\n",
      "training @ iter =  225800\n",
      "training @ iter =  225900\n",
      "training @ iter =  226000\n",
      "training @ iter =  226100\n",
      "training @ iter =  226200\n",
      "training @ iter =  226300\n",
      "training @ iter =  226400\n",
      "training @ iter =  226500\n",
      "training @ iter =  226600\n",
      "training @ iter =  226700\n",
      "training @ iter =  226800\n",
      "training @ iter =  226900\n",
      "training @ iter =  227000\n",
      "training @ iter =  227100\n",
      "training @ iter =  227200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7cd4b78a083b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3bmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_lenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhw3bmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest_dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtest_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnkerns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/extern/final/dropconnect/src/hw3bmnist.py\u001b[0m in \u001b[0;36mtest_dropout\u001b[1;34m(learning_rate, n_epochs, nkerns, batch_size, verbose, fileName)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     predictions = train_nn(train_model, validate_model, test_model, getPredictedValue,\n\u001b[1;32m--> 223\u001b[1;33m         n_train_batches, n_valid_batches, n_test_batches, n_epochs, learning_rate, verbose)\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/extern/final/dropconnect/src/hw3_nn.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(train_model, validate_model, test_model, getPredictedValue, n_train_batches, n_valid_batches, n_test_batches, n_epochs, learning_rate, verbose)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training @ iter = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalidation_frequency\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoContext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3bmnist import test_lenet\n",
    "from hw3bmnist import test_dropout\n",
    "test_dropout(batch_size = 20,nkerns = [32,64],learning_rate = 0.01,verbose=True,n_epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "Yo Man\n",
      "... training\n",
      "print(validation_frequency) = 2500\n",
      "training @ iter =  0\n",
      "training @ iter =  100\n",
      "training @ iter =  200\n",
      "training @ iter =  300\n",
      "training @ iter =  400\n",
      "training @ iter =  500\n",
      "training @ iter =  600\n",
      "training @ iter =  700\n",
      "training @ iter =  800\n",
      "training @ iter =  900\n",
      "training @ iter =  1000\n",
      "training @ iter =  1100\n",
      "training @ iter =  1200\n",
      "training @ iter =  1300\n",
      "training @ iter =  1400\n",
      "training @ iter =  1500\n",
      "training @ iter =  1600\n",
      "training @ iter =  1700\n",
      "training @ iter =  1800\n",
      "training @ iter =  1900\n",
      "training @ iter =  2000\n",
      "training @ iter =  2100\n",
      "training @ iter =  2200\n",
      "training @ iter =  2300\n",
      "training @ iter =  2400\n",
      "epoch 1, minibatch 2500/2500, validation error 31.300000 %\n",
      "     epoch 1, minibatch 2500/2500, test error of best model 31.750000 %\n",
      "training @ iter =  2500\n",
      "training @ iter =  2600\n",
      "training @ iter =  2700\n",
      "training @ iter =  2800\n",
      "training @ iter =  2900\n",
      "training @ iter =  3000\n",
      "training @ iter =  3100\n",
      "training @ iter =  3200\n",
      "training @ iter =  3300\n",
      "training @ iter =  3400\n",
      "training @ iter =  3500\n",
      "training @ iter =  3600\n",
      "training @ iter =  3700\n",
      "training @ iter =  3800\n",
      "training @ iter =  3900\n",
      "training @ iter =  4000\n",
      "training @ iter =  4100\n",
      "training @ iter =  4200\n",
      "training @ iter =  4300\n",
      "training @ iter =  4400\n",
      "training @ iter =  4500\n",
      "training @ iter =  4600\n",
      "training @ iter =  4700\n",
      "training @ iter =  4800\n",
      "training @ iter =  4900\n",
      "epoch 2, minibatch 2500/2500, validation error 13.660000 %\n",
      "     epoch 2, minibatch 2500/2500, test error of best model 13.820000 %\n",
      "training @ iter =  5000\n",
      "training @ iter =  5100\n",
      "training @ iter =  5200\n",
      "training @ iter =  5300\n",
      "training @ iter =  5400\n",
      "training @ iter =  5500\n",
      "training @ iter =  5600\n",
      "training @ iter =  5700\n",
      "training @ iter =  5800\n",
      "training @ iter =  5900\n",
      "training @ iter =  6000\n",
      "training @ iter =  6100\n",
      "training @ iter =  6200\n",
      "training @ iter =  6300\n",
      "training @ iter =  6400\n",
      "training @ iter =  6500\n",
      "training @ iter =  6600\n",
      "training @ iter =  6700\n",
      "training @ iter =  6800\n",
      "training @ iter =  6900\n",
      "training @ iter =  7000\n",
      "training @ iter =  7100\n",
      "training @ iter =  7200\n",
      "training @ iter =  7300\n",
      "training @ iter = "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from hw3_utils import shared_dataset, load_data\n",
    "from hw3_nn import LogisticRegression, HiddenLayer, myMLP, LeNetConvPoolLayer, train_nn, DropConnect\n",
    "from hw3bmnist import test_lenet\n",
    "from hw3bmnist import test_dropout\n",
    "test_dropout(batch_size = 20,nkerns = [32,64],learning_rate = 0.01,verbose=True,n_epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
